{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM char generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0FLCej6Lz-P",
        "colab_type": "text"
      },
      "source": [
        "# Character level RNN (LSTM)\n",
        "\n",
        "We will be building a text generator based of Mukhtar Auezov novels. Filrst, __make sure to upload the text file you want to generate text from__.\n",
        "\n",
        "We will be using LSTM because they work well with long sequences of data. By long sequence, it was meant to say that if we pass for example sequence length as 50, then LSTM is less likely to have exploding/vanishing gradients, whereas RNN most defintely will.\n",
        "\n",
        "Let's fucking nail this project. I hope I can finish it within today."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcfaTDs7rMPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQWzRBPsxXWk",
        "colab_type": "text"
      },
      "source": [
        "## Reading and preprocessing of the data\n",
        "\n",
        "Data is simply concatenation of 3 books of kazakh writer Mukhtar Auezov - \"The Path of Abay I\", \"The Path of Abay II\", and \"Karash-karash\" into one text file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miRvYdIwwhAe",
        "colab_type": "code",
        "outputId": "6770e588-a4f7-4ad2-a568-e954f17e3e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "FILE_NAME = 'whole.txt'\n",
        "\n",
        "with open(FILE_NAME, 'r') as f:\n",
        "  text=f.read()\n",
        "\n",
        "chars = tuple(set(text))\n",
        "\n",
        "print('First 100 characters of the text:')\n",
        "print(repr(text[:100]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 100 characters of the text:\n",
            "'Абай жолы. І кітап\\n\\xa0\\nҚАЙТҚАНДА\\n\\n 1\\n\\nҮш күндік жолдың бүгінгі, соңғы күніне шәкірт бала барын салды.\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJNfSG0Xx7G3",
        "colab_type": "code",
        "outputId": "1b05b707-7f32-44f0-af0c-d749b2c99280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "int2char = dict(enumerate(chars))\n",
        "char2int = {cc: ii for ii, cc in int2char.items()}\n",
        "\n",
        "encoded = np.array([char2int[cc] for cc in text])\n",
        "\n",
        "print('First 100 encoded characters of the text:')\n",
        "print(repr(encoded[:100]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 100 encoded characters of the text:\n",
            "array([ 72,   6, 106,  85,  69,  63,  47,  88,  51,  31,  69,  17,  69,\n",
            "        60,  33,  18, 106,   1, 111,  52, 111,  56,  72,  74,  61,  56,\n",
            "        72,  29,  82,  72, 111, 111,  69,   3, 111, 111,  75,  19,  69,\n",
            "        60,  99,  55,  30,  33,  60,  69,  63,  47,  88,  30,  51,  34,\n",
            "        69,   6,  99,  59,  33,  55,  59,  33,  67,  69, 101,  47,  34,\n",
            "        95,  51,  69,  60,  99,  55,  33,  55,  36,  69,  19,  97,  60,\n",
            "        33,  15,  18,  69,   6, 106,  88, 106,  69,   6, 106,  15,  51,\n",
            "        55,  69, 101, 106,  88,  30,  51,  31, 111])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8z1Ip2X1dEY",
        "colab_type": "text"
      },
      "source": [
        "__NOTE__:\n",
        "\n",
        "Regarding the `*` operation in python:\n",
        "* Single star `*` operation unpacks the list/tuple contents\n",
        "* Double start `**`operation unpack the dictionary contents\n",
        "\n",
        "Code example:\n",
        "```\n",
        ">>> def foo(x,y,z):\n",
        "              print(\"x=\" + str(x))\n",
        "              print(\"y=\" + str(y))\n",
        "              print(\"z=\" + str(z))\n",
        "              \n",
        ">>> mylist = [1,2,3]\n",
        ">>> foo(*mylist)\n",
        "x=1\n",
        "y=2\n",
        "z=3\n",
        "\n",
        ">>> mydict = {'x':1,'y':2,'z':3}\n",
        ">>> foo(**mydict)\n",
        "x=1\n",
        "y=2\n",
        "z=3\n",
        "\n",
        ">>> mytuple = (1, 2, 3)\n",
        ">>> foo(*mytuple)\n",
        "x=1\n",
        "y=2\n",
        "z=3\n",
        "\n",
        ">>> def sum(*values):\n",
        "              s = 0\n",
        "              for v in values:\n",
        "                  s = s + v\n",
        "              return s\n",
        "\n",
        ">>> sum(1, 2, 3, 4, 5)\n",
        "15\n",
        "\n",
        ">>> def get_a(**values):\n",
        "              return values['a']\n",
        "\n",
        ">>> get_a(a=1, b=2)\n",
        "a\n",
        "\n",
        ">>> def sum(*values, **options):\n",
        "              s = 0\n",
        "              for i in values:\n",
        "                  s = s + i\n",
        "              if \"neg\" in options:\n",
        "                  if options[\"neg\"]:\n",
        "                      s = -s\n",
        "              return s\n",
        "\n",
        ">>> sum(1, 2, 3, 4, 5)\n",
        "15\n",
        ">>> sum(1, 2, 3, 4, 5, neg=True)\n",
        "-15\n",
        ">>> sum(1, 2, 3, 4, 5, neg=False)\n",
        "15\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viq3bLO5weP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "  # arr argument is one dimensional vector of int encoded values\n",
        "  \n",
        "  # Create vector of new size that has the right shape of one-hot encoding\n",
        "  one_hot_vector = np.zeros((arr.size, n_labels))\n",
        "  \n",
        "  # Transform the values into one-hot encodings\n",
        "  one_hot_vector[np.arange(arr.size), arr.flatten()] = 1\n",
        "  \n",
        "  # Save the shape, flatten the array, and encode the values\n",
        "  return one_hot_vector.reshape((*arr.shape, n_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdMfslMs7Zgp",
        "colab_type": "code",
        "outputId": "b2873cc3-6722-4db5-eedf-3666d53f13bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "temp = np.array([0,1,2,3,4,5,6,7,8,9]).reshape(2,5)\n",
        "print(f'Input array is:\\n{temp}\\n')\n",
        "print(f'Encoded array is:\\n{one_hot_encode(temp, 10)}')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input array is:\n",
            "[[0 1 2 3 4]\n",
            " [5 6 7 8 9]]\n",
            "\n",
            "Encoded array is:\n",
            "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyJZcY708TGi",
        "colab_type": "text"
      },
      "source": [
        "## Creating batches\n",
        "\n",
        "This one is interesting part of the coding. So, the inputs for this function will be `array`, `batch_size`, `seq_length`.\n",
        "\n",
        "It should return a generator, that will output the values for input - `x` and output `y`. `y` is `[batch_size,sequence_length]` array shifted by one from `x`\n",
        "\n",
        "__NOTE__:\n",
        "\n",
        "So, at first I was very certain that the way I would do the batch generating would be perfectly logical and corrent, but never in my life I was so wrong.\n",
        "\n",
        "So, with the shape of array `[batch_size,sequence_length]` it is hard to target values of current batch. \n",
        "\n",
        "For instance:\n",
        "\n",
        "`input_array` = `[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]`\n",
        "\n",
        "`transformed_array` = \n",
        "```\n",
        "[[[ 0  1  2  3]\n",
        "  [ 4  5  6  7]]\n",
        " [[ 8  9 10 11]\n",
        "  [12 13 14 15]]]\n",
        "  ```\n",
        "  \n",
        "and `x`, `y` should be as follow for the first batch:\n",
        " \n",
        "`x`: \n",
        "```\n",
        "[[ 0  1  2  3]\n",
        "  [ 4  5  6  7]]\n",
        "```\n",
        "and `y`:\n",
        "```\n",
        "[[ 1  2  3  4]\n",
        "  [ 5  6  7  8]]\n",
        "\n",
        "```\n",
        "\n",
        "So with former `transformed array` it is really difficult to get the targets for input batch, so instead we could organize our `transformed_array` as follows:\n",
        "```\n",
        "[[ 0  1  2  3  4  5  6  7]\n",
        " [ 8  9 10 11 12 13 14 15]]\n",
        "```\n",
        "sliding by window of `[batch_size, seq_len]`, so the resulting `x`'s and `y`'s will be as follows:\n",
        "`x`:\n",
        "```\n",
        "[[0  1  2  3]   [[ 4  5  6  7]\n",
        "  [8  9 10 11]]   [12 13 14 15]]\n",
        "```\n",
        "`y`:\n",
        "```\n",
        "[[1  2  3  4]   [[ 5  6  7  0]\n",
        "  [9 10 11 12]]   [13 14 15  8]]\n",
        "```\n",
        "\n",
        "So, in total we will have `batch_size` sequences that do not have proper output - the last batch, but if the data is big, it should cause any problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD2uyx4jDqiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mini_batches(array, batch_size, seq_length):\n",
        "  \n",
        "  items_per_batch = batch_size * seq_length\n",
        "  num_batches = array.shape[0] // items_per_batch\n",
        "  array = array[:num_batches * items_per_batch]\n",
        "  \n",
        "  n_shape = (batch_size, seq_length*num_batches, *array.shape[1:])\n",
        "  array = array.reshape(n_shape)\n",
        "  \n",
        "  for i in range(0, array.shape[1], seq_length):\n",
        "    x = array[:, i:i+seq_length]\n",
        "    y = np.zeros_like(x)\n",
        "    try:\n",
        "      y[:,:-1], y[:,-1] = x[:,1:], array[:,i+seq_length]\n",
        "    except IndexError:\n",
        "      y[:,:-1], y[:,-1] = x[:,1:], array[:,0]\n",
        "    yield x, y\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfDHqwzY2W0x",
        "colab_type": "text"
      },
      "source": [
        "### Testing shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvj7GjS_Jhzu",
        "colab_type": "code",
        "outputId": "4b2b0abc-bddb-49ca-8ec4-00f75cf5c2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "temp = np.arange(22)\n",
        "print('With batch size: 2, sequence length: 3 we have following:\\n')\n",
        "print(f'Our original array is:\\n{temp}\\n')\n",
        "print(f'Transformed array is:\\n{temp.reshape(2,-1)}\\n')\n",
        "\n",
        "gen = get_mini_batches(temp, 2, 3)\n",
        "x, y = next(gen)\n",
        "print(f'First batch of mini-sequence (input and target):\\n{x}\\n\\n{y}\\n\\n')\n",
        "\n",
        "x, y = next(gen)\n",
        "print(f'Second batch of mini-sequence (input and target):\\n{x}\\n\\n{y}\\n\\n')\n",
        "\n",
        "x, y = next(gen)\n",
        "print(f'Third batch of mini-sequence (input and target):\\n{x}\\n\\n{y}\\n\\n')\n",
        "\n",
        "print('Make sure to understand that instead of integer array (values), we will \\nhave one-hot encoded vectors of vocabulary length, i.e. different shape.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With batch size: 2, sequence length: 3 we have following:\n",
            "\n",
            "Our original array is:\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
            "\n",
            "Transformed array is:\n",
            "[[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            " [11 12 13 14 15 16 17 18 19 20 21]]\n",
            "\n",
            "First batch of mini-sequence (input and target):\n",
            "[[ 0  1  2]\n",
            " [ 9 10 11]]\n",
            "\n",
            "[[ 1  2  3]\n",
            " [10 11 12]]\n",
            "\n",
            "\n",
            "Second batch of mini-sequence (input and target):\n",
            "[[ 3  4  5]\n",
            " [12 13 14]]\n",
            "\n",
            "[[ 4  5  6]\n",
            " [13 14 15]]\n",
            "\n",
            "\n",
            "Third batch of mini-sequence (input and target):\n",
            "[[ 6  7  8]\n",
            " [15 16 17]]\n",
            "\n",
            "[[ 7  8  0]\n",
            " [16 17  9]]\n",
            "\n",
            "\n",
            "Make sure to understand that instead of integer array (values), we will \n",
            "have one-hot encoded vectors of vocabulary length, i.e. different shape.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YBB9bFD6T8w",
        "colab_type": "code",
        "outputId": "99e9f1ab-11a7-4937-9d02-c776181ca093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "batches = get_mini_batches(encoded, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "# printing out the first 10 items in a sequence\n",
        "print('Testing on actual data:\\n')\n",
        "print('x\\n', x[:10, :10])\n",
        "print('\\ny\\n', y[:10, :10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on actual data:\n",
            "\n",
            "x\n",
            " [[ 72   6 106  85  69  63  47  88  51  31]\n",
            " [ 36  55  69  60  36  76  30  36  69 106]\n",
            " [106 101  51   1 111  64 106  85  18  64]\n",
            " [ 55  69 101  47  34  69  95 106  55 106]\n",
            " [ 88  69  63  99  15  20  36  60  60  36]\n",
            " [ 69  63  47  15  95 106  69 106  18  18]\n",
            " [  1  69  60  36  18  35   1  67  69  20]\n",
            " [ 69  63 106  11 106   1  69  36 101  18]]\n",
            "\n",
            "y\n",
            " [[  6 106  85  69  63  47  88  51  31  69]\n",
            " [ 55  69  60  36  76  30  36  69 106 101]\n",
            " [101  51   1 111  64 106  85  18  64 106]\n",
            " [ 69 101  47  34  69  95 106  55 106 111]\n",
            " [ 69  63  99  15  20  36  60  60  36  69]\n",
            " [ 63  47  15  95 106  69 106  18  18  51]\n",
            " [ 69  60  36  18  35   1  67  69  20  47]\n",
            " [ 63 106  11 106   1  69  36 101  18  33]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQnmptgO9wuK",
        "colab_type": "text"
      },
      "source": [
        "## Model LSTM\n",
        "\n",
        "LSTM is a little complicated than RNN. It has more complex structure than RNN. Below is the structure of the LSTM:\n",
        "\n",
        "![LSTM](https://res.mdpi.com/information/information-10-00105/article_deploy/html/images/information-10-00105-g002.png)\n",
        "\n",
        "So, LSTM has 4 gates:\n",
        "* Input gate - $i_t$ \n",
        "* Forget gate - $i_f$\n",
        "* Cell gate - $g_i$\n",
        "* Output gate - $o_i$\n",
        "\n",
        "and 2 states:\n",
        "* Cell state - $c_i$\n",
        "* Hidden state $h_i$\n",
        "\n",
        "In number, it looks as follows:\n",
        "$$\n",
        "f_{t}=\\sigma(W_{if}x_{t} + b_{if} + W_{hhf}h_{t-1} + b_{hhf}) \\\\\n",
        "i_{t}=\\sigma(W_{ii}x_{t} + b_{ii} + W_{hhi}h_{t-1} + b_{hhi}) \\\\\n",
        "g_{t}=tanh(W_{ig}x_{t} + b_{ig} + W_{hhg}h_{t-1} + b_{hhg}) \\\\\n",
        "o_{t}=\\sigma(W_{io}x_{t} + b_{io} + W_{hho}h_{t-1} + b_{hho}) \\\\\n",
        "c_{t}=f_{t}\\times c_{t-1} + i_{t}\\times g_{t} \\\\\n",
        "h_{t}= o_{t}\\times tanh(c_{t})\\\\\n",
        "$$\n",
        "\n",
        "where $W_{if, ii, ig, io}\\in R^{m\\times n}$, $x_i\\in R^{n\\times 1}$, $W_{hhf, hhi, hhg, hho}\\in R^{m\\times m}$, $h_i\\in R^{m\\times 1}$ and $\\times$ is Hadamard product (like matrix addition, except it is multiplication).\n",
        "\n",
        "Inputs for __LSTM__:\n",
        "\n",
        ">__Input__\n",
        "* __input__ of shape _(seq_len, batch, input_size)_: tensor containing the features of the input sequence.\n",
        "* __h_0__ of shape _(num_layers * num_directions, batch, hidden_size)_: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, `num_directions` should be 2, else it should be 1.\n",
        "* __c_0__ of shape (_num_layers * num_directions, batch, hidden_size_): tensor containing the initial cell state for each element in the batch.\n",
        ">\n",
        ">If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
        ">\n",
        ">__Output__\n",
        "* __output__ of shape _(seq_len, batch, num_directions * hidden_size)_: tensor containing the output features `(h_t)` from the last layer of the RNN, for each `t`.\n",
        "* __h_n__ of shape _(num_layers * num_directions, batch, hidden_size)_: tensor containing the hidden state for `t = seq_len`.\n",
        "* __c_n__ of shape (_num_layers * num_directions, batch, hidden_size_): tensor containing the cell state for t = seq_len.\n",
        "\n",
        "\n",
        "\n",
        "For reference, please follow this link regarding [Pytorch's `LSTM class`](https://pytorch.org/docs/stable/nn.html#lstm)\n",
        "\n",
        "\n",
        "Below is class definition of LSTM with option of switching to GRU and RNN cells for comparison aims."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbGBJkIbWokf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, tokens, n_hidden=256, n_layers=2, \n",
        "               dropout=0.5, mode='LSTM'):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.drop_val = dropout\n",
        "    self.n_layers = n_layers\n",
        "    self.n_hidden = n_hidden\n",
        "    self.mode = mode\n",
        "    \n",
        "    self.chars = tokens\n",
        "    self.int2char = dict(enumerate(tokens))\n",
        "    self.char2int = {cc: ii for ii, cc in self.int2char.items()}\n",
        "    \n",
        "    if mode == 'LSTM':\n",
        "      self.rnn = nn.LSTM(len(tokens), n_hidden, n_layers, \n",
        "                         batch_first=True, dropout=dropout)\n",
        "    elif mode == 'GRU':\n",
        "      self.rnn = nn.GRU(len(tokens), n_hidden, n_layers, \n",
        "                        batch_first=True, dropout=dropout)\n",
        "    else:\n",
        "      self.rnn = nn.RNN(len(tokens), n_hidden, n_layers, \n",
        "                        batch_first=True, dropout=dropout)\n",
        "    \n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    self.fc = nn.Linear(n_hidden, len(tokens))\n",
        "  \n",
        "  def forward(self, b_x, b_h):\n",
        "    \n",
        "    out, hidden = self.rnn(b_x, b_h)\n",
        "    \n",
        "    out = self.dropout(out)\n",
        "#     Regarding the contiguous refer to \n",
        "#     https://stackoverflow.com/questions/48915810/pytorch-contiguous\n",
        "    out = out.contiguous().view(-1, self.n_hidden)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDK3l-VElSey",
        "colab_type": "text"
      },
      "source": [
        "__NOTE__: \n",
        "\n",
        "We need to have to _contigious_ output in order to compute the loss, since the criterion function (_CrossEntropyLoss_) will expect the outputs to be of the shape `[N, C]`, where `N` is the number of the items, and `C` is the classes (class scores).\n",
        "\n",
        "Regarding the __`contiguous`__ - sets the vectors aligned, since some operations during backpropagation require vectors to be contiguous. More on [here](https://stackoverflow.com/questions/48915810/pytorch-contiguous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCURx_JS4mIo",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Testing model input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sax0PsWgyjC7",
        "colab_type": "code",
        "outputId": "5c48f22f-cecb-4969-f6c5-4e623ca4a810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "print('Testing model input-output\\n')\n",
        "seq_length = 50\n",
        "input_size = 100\n",
        "output_size = 200\n",
        "hidden_size = 400\n",
        "print(f'Input size: {input_size}, sequence length: {seq_length}, output size: {output_size}, hidden size: {hidden_size}\\n')\n",
        "\n",
        "lstm = nn.LSTM(input_size, hidden_size, 2, batch_first=True)\n",
        "b_x = torch.Tensor(np.random.randn(1,seq_length,input_size))\n",
        "print(f'Shape of input data: {b_x.shape}\\n')\n",
        "\n",
        "out, hidden = lstm(b_x, None)\n",
        "\n",
        "print(f'Output shape of lstm {out.shape}')\n",
        "print(f'Hidden shape of lstm {hidden[0].shape}')\n",
        "print(f'Cell shape of lstm {hidden[1].shape}')\n",
        "\n",
        "out = out.contiguous().view(-1, hidden_size)\n",
        "print(f'Transformed output shape of lstm (for cross-entropy loss compatibility): {out.shape}')\n",
        "\n",
        "fc = nn.Linear(hidden_size, output_size)\n",
        "out = fc(out)\n",
        "print(f'Output shape of fc {out.shape}\\n\\n')\n",
        "\n",
        "print('Testing with get_mini_batches() function\\n')\n",
        "temp = np.array([np.multiply([1]*10,i) for i in range(20000)])\n",
        "batch_size = 4\n",
        "seq_length = 20\n",
        "input_size = 10\n",
        "output_size = 40\n",
        "hidden_size = 80\n",
        "print(f'Input size: {input_size}, sequence length: {seq_length}, output size: {output_size}, hidden size: {hidden_size}\\n')\n",
        "\n",
        "b_x, b_y = next(get_mini_batches(temp, batch_size, seq_length))\n",
        "print(f'Shape of input data: {b_x.shape}\\n')\n",
        "print(f'b_x:\\n{b_x[:, :10, 0]}')\n",
        "print(f'b_y:\\n{b_y[:, :10, 0]}\\n')\n",
        "\n",
        "lstm = nn.LSTM(input_size, hidden_size, 2, batch_first=True)\n",
        "out, hidden = lstm(torch.Tensor(b_x), None)\n",
        "\n",
        "print(f'Output shape of lstm {out.shape}')\n",
        "print(f'Hidden shape of lstm {hidden[0].shape}')\n",
        "print(f'Cell shape of lstm {hidden[1].shape}')\n",
        "\n",
        "out = out.contiguous().view(-1, hidden_size)\n",
        "print(f'Transformed output shape of lstm (for cross-entropy loss compatibility): {out.shape}')\n",
        "\n",
        "fc = nn.Linear(hidden_size, output_size)\n",
        "out = fc(out)\n",
        "print(f'Output shape of fc {out.shape}\\n\\n')\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing model input-output\n",
            "\n",
            "Input size: 100, sequence length: 50, output size: 200, hidden size: 400\n",
            "\n",
            "Shape of input data: torch.Size([1, 50, 100])\n",
            "\n",
            "Output shape of lstm torch.Size([1, 50, 400])\n",
            "Hidden shape of lstm torch.Size([2, 1, 400])\n",
            "Cell shape of lstm torch.Size([2, 1, 400])\n",
            "Transformed output shape of lstm (for cross-entropy loss compatibility): torch.Size([50, 400])\n",
            "Output shape of fc torch.Size([50, 200])\n",
            "\n",
            "\n",
            "Testing with get_mini_batches() function\n",
            "\n",
            "Input size: 10, sequence length: 20, output size: 40, hidden size: 80\n",
            "\n",
            "Shape of input data: (4, 20, 10)\n",
            "\n",
            "b_x:\n",
            "[[    0     1     2     3     4     5     6     7     8     9]\n",
            " [ 5000  5001  5002  5003  5004  5005  5006  5007  5008  5009]\n",
            " [10000 10001 10002 10003 10004 10005 10006 10007 10008 10009]\n",
            " [15000 15001 15002 15003 15004 15005 15006 15007 15008 15009]]\n",
            "b_y:\n",
            "[[    1     2     3     4     5     6     7     8     9    10]\n",
            " [ 5001  5002  5003  5004  5005  5006  5007  5008  5009  5010]\n",
            " [10001 10002 10003 10004 10005 10006 10007 10008 10009 10010]\n",
            " [15001 15002 15003 15004 15005 15006 15007 15008 15009 15010]]\n",
            "\n",
            "Output shape of lstm torch.Size([4, 20, 80])\n",
            "Hidden shape of lstm torch.Size([2, 4, 80])\n",
            "Cell shape of lstm torch.Size([2, 4, 80])\n",
            "Transformed output shape of lstm (for cross-entropy loss compatibility): torch.Size([80, 80])\n",
            "Output shape of fc torch.Size([80, 40])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvySNrbO4zo8",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "### Regarding the parameters of LSTM\n",
        "\n",
        "Below is function for printing parameters of given model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7RpIg8qvojr",
        "colab_type": "code",
        "outputId": "d6336534-fb4c-4dbe-fec7-253e6ca1b8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def printParams(model):\n",
        "  total = 0\n",
        "  totalGrad = 0\n",
        "  for name, param in model.named_parameters():\n",
        "    total += param.numel()\n",
        "    print(f'Name:{name:>20}, shape: {str(param.shape):>25}, total params: {param.numel() if param.requires_grad else 0:>10}, grad params: {param.numel() if param.requires_grad else 0:>10}')\n",
        "  print(f'\\nTotal number of parameters is {total}')\n",
        "\n",
        "lstm = nn.LSTM(100, 200, 2)\n",
        "printParams(lstm)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name:        weight_ih_l0, shape:    torch.Size([800, 100]), total params:      80000, grad params:      80000\n",
            "Name:        weight_hh_l0, shape:    torch.Size([800, 200]), total params:     160000, grad params:     160000\n",
            "Name:          bias_ih_l0, shape:         torch.Size([800]), total params:        800, grad params:        800\n",
            "Name:          bias_hh_l0, shape:         torch.Size([800]), total params:        800, grad params:        800\n",
            "Name:        weight_ih_l1, shape:    torch.Size([800, 200]), total params:     160000, grad params:     160000\n",
            "Name:        weight_hh_l1, shape:    torch.Size([800, 200]), total params:     160000, grad params:     160000\n",
            "Name:          bias_ih_l1, shape:         torch.Size([800]), total params:        800, grad params:        800\n",
            "Name:          bias_hh_l1, shape:         torch.Size([800]), total params:        800, grad params:        800\n",
            "\n",
            "Total number of parameters is 563200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V2VQlA_trGX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The outputs of the parameters of the LSTM layer is as following:\n",
        "```\n",
        ">>> lstm = nn.LSTM(i_size, h_size, n)\n",
        ">>> for name, param in lstm.named_parameters():\n",
        "              print(f'Name:{name:>15}, shape: {str(param.shape):>25}, total params: {param.numel() if param.requires_grad else 0:>6}, grad params: {param.numel() if param.requires_grad else 0:>6}')\n",
        " \n",
        "Name: weight_ih_l0,     shape: torch.Size([4*h_size, i_size]), total params: 4*h_size*i_size, ...\n",
        "Name: weight_hh_l0,     shape: torch.Size([4*h_size, h_size]), total params: 4*h_size*h_size, ...\n",
        "Name:   bias_ih_l0,     shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "Name:   bias_hh_l0,     shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "Name: weight_ih_l1,     shape: torch.Size([4*h_size, h_size]), total params: 4*h_size*h_size, ...\n",
        "Bame: weight_hh_l1,     shape: torch.Size([4*h_size, h_size]), total params: 4*h_size*h_size, ...\n",
        "Name:   bias_ih_l1,     shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "Name:   bias_hh_l1,     shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "...\n",
        "Name: weight_ih_l[n-1], shape: torch.Size([4*h_size, h_size]), total params: 4*h_size*h_size, ...\n",
        "Bame: weight_hh_l[n-1], shape: torch.Size([4*h_size, h_size]), total params: 4*h_size*h_size, ...\n",
        "Name:   bias_ih_l[n-1], shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "Name:   bias_hh_l[n-1], shape: torch.Size([4*h_size]),         total params: 4*h_size, ...\n",
        "```\n",
        "By the formulation of the RNN formulation,\n",
        "$$\n",
        "f_{t}=\\sigma(W_{if}x_{t} + b_{if} + W_{hhf}h_{t-1} + b_{hhf}) \\\\\n",
        "i_{t}=\\sigma(W_{ii}x_{t} + b_{ii} + W_{hhi}h_{t-1} + b_{hhi}) \\\\\n",
        "g_{t}=tanh(W_{ig}x_{t} + b_{ig} + W_{hhg}h_{t-1} + b_{hhg}) \\\\\n",
        "o_{t}=\\sigma(W_{io}x_{t} + b_{io} + W_{hho}h_{t-1} + b_{hho}) \\\\\n",
        "c_{t}=f_{t}\\times c_{t-1} + i_{t}\\times g_{t} \\\\\n",
        "h_{t}= o_{t}\\times tanh(c_{t})\\\\\n",
        "$$\n",
        "\n",
        "The corresponding values of the parameters are as follows:\n",
        "* `weight_ih_ln` is concatenated weights of $W_{if, ii, ig, io}$ of n-th layer\n",
        "* `weight_hh_ln` is concatenated weights of $W_{hhf, hhi, hhg, hho}$ of n-th layer\n",
        "* `bias_ih_ln` is concatenated weights of $b_{if, ii, ig, io}$ of n-th layer\n",
        "* `bias_hh_ln` is concatenated weights of $b_{hhf, hhi, hhg, hho}$ of n-th layer\n",
        "\n",
        "---\n",
        "## Training LSTM\n",
        "\n",
        "Here's some good advice from Andrej Karpathy on training the network. Link to [where it originally came from](https://github.com/karpathy/char-rnn#tips-and-tricks).\n",
        "\n",
        "> ## Tips and Tricks\n",
        "\n",
        ">### Monitoring Validation Loss vs. Training Loss\n",
        ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
        "\n",
        "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
        "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
        "\n",
        "> ### Approximate number of parameters\n",
        "\n",
        "> The two most important parameters that control the model are `n_hidden` and `n_layers`. I would advise that you always use `n_layers` of either 2/3. The `n_hidden` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
        "\n",
        "> - The number of parameters in your model. This is printed when you start training.\n",
        "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
        "\n",
        ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
        "\n",
        "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `n_hidden` larger.\n",
        "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
        "\n",
        "> ### Best models strategy\n",
        "\n",
        ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
        "\n",
        ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
        "\n",
        ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative.\n",
        "\n",
        "To read more on RNN:\n",
        "* [Chris Olah's LSTM post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "* [Edwin Chen's LSTM post](http://blog.echen.me/2017/05/30/exploring-lstms/)\n",
        "* [Andrej Karpathy's blog post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "* [Andrej Karpathy's lecture on RNNs and LSTMs from CS231n](https://www.youtube.com/watch?v=iX5V1WpxxkY)\n",
        "\n",
        "---\n",
        "So, our data is about __2MB__ in size, thus I think __900000__ parameters is OK for now. Let's try it.\n",
        "\n",
        "_Details about training_:\n",
        "* Always use `detach()` for detaching tensor from the graph, [source](https://discuss.pytorch.org/t/the-difference-between-data-and-detach/30926).\n",
        "* No need to manually initialize the weights for the hidden and cell states of the LSTM, since if we pass `None`, it will automatically create zero-initialized tensor of necessary size.\n",
        "* Difference between `function(...)` and `function_(...)` is the the __former__ applies function on __new object__, and __latter__ one applies function __in-place__\n",
        "* We clip - `nn.utils.clip_grad_norm_(model.parameters(), clip)` - the gradients in order to avoid _exploding gradient problem_, especially if we have long sequences of training data.\n",
        "\n",
        "Following two functions are helper function to sampling from our trained model: \n",
        "* `predict(...)` - returns the next character given current one and hidden state of the model with randomness given by `topk` parameter (returns the random next character based on top k characters from model with probability given by model). \n",
        "* `sample(...)` - return concatened output of model for `size` iterations given the prefix word `prefix` for generating initial hidden state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW72VwW9FCMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, c, h=None, topk=None):\n",
        "  c = np.array(model.char2int.get(c))\n",
        "  c = one_hot_encode(c, len(model.chars))\n",
        "  c = c.reshape(1,1,-1)\n",
        "  c = torch.Tensor(c).to(device)\n",
        "  \n",
        "  p, h = model(c, h)\n",
        "  \n",
        "  p = p.detach().squeeze()\n",
        "  p = F.softmax(p, dim=0)\n",
        "  \n",
        "  if device == 'cuda':\n",
        "    p = p.cpu()\n",
        "  \n",
        "  if topk is None:\n",
        "    top_ch = np.arange(len(model.chars))\n",
        "  else:\n",
        "    p, top_ch = p.topk(topk)\n",
        "  \n",
        "  p, top_ch = p.numpy(), top_ch.numpy()\n",
        "  c = np.random.choice(top_ch, p=p/p.sum())\n",
        "  \n",
        "  return model.int2char.get(c), h\n",
        "\n",
        "def sample(model, topk, size, prefix='Абай'):\n",
        "  h = None\n",
        "  \n",
        "  for c in prefix:\n",
        "    _, h = predict(model, c, h, topk)\n",
        "  \n",
        "  output = []\n",
        "  for i in range(size):\n",
        "    c, h = predict(model, c, h, topk)\n",
        "    output.append(c)\n",
        "  \n",
        "  return prefix + ''.join(output)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izSyz3-J4rL2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Defining model and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUE51CW6BV9b",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "\n",
        "Function `train(...)` actually trains model for given `epochs` and returns training and validation loss scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rqTNTejrJuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, text, epochs=200, seq_length=200, batch_size=256, \n",
        "          clip=5, train_frac=0.8,lr=0.001, save_rate=None, \n",
        "          topk=5, sample_char_size=100):\n",
        "  \n",
        "  encoded = np.array([model.char2int[c] for c in text])\n",
        "  \n",
        "  train_idx = int(len(encoded)*train_frac)\n",
        "  encoded_train = encoded[:train_idx]\n",
        "  encoded_valid = encoded[train_idx:]\n",
        "\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  loss_hist_train = []\n",
        "  loss_hist_valid = []\n",
        "\n",
        "  for e in range(1, epochs+1):\n",
        "\n",
        "    hidden = None\n",
        "\n",
        "    e_loss = 0\n",
        "    t = time.time()\n",
        "\n",
        "    for b_x, b_y in get_mini_batches(encoded_train, batch_size, seq_length):\n",
        "\n",
        "      oh_x = one_hot_encode(b_x, len(chars))\n",
        "\n",
        "      oh_x, b_y = torch.Tensor(oh_x).to(device), torch.Tensor(b_y).to(device)\n",
        "\n",
        "      if model.mode == 'LSTM':\n",
        "        hidden = None if hidden is None else tuple((e.detach() for e in hidden))\n",
        "      else:\n",
        "        hidden = None if hidden is None else hidden.detach()\n",
        "\n",
        "      b_y_pred, hidden = model(oh_x, hidden)\n",
        "      loss = criterion(b_y_pred, b_y.view(seq_length*batch_size).long())\n",
        "\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optim.step()\n",
        "\n",
        "      e_loss += loss.item()\n",
        "\n",
        "    e_loss = e_loss / (len(encoded_train)//(batch_size*seq_length))\n",
        "    loss_hist_train.append(e_loss)\n",
        "    e_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      hidden = None\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      for b_x, b_y in get_mini_batches(encoded_valid, batch_size, seq_length):\n",
        "\n",
        "        oh_x = one_hot_encode(b_x, len(chars))\n",
        "\n",
        "        oh_x, b_y = torch.Tensor(oh_x).to(device), torch.Tensor(b_y).to(device)\n",
        "\n",
        "        b_y_pred, hidden = model(oh_x, hidden)\n",
        "        loss = criterion(b_y_pred, b_y.view(seq_length*batch_size).long())\n",
        "\n",
        "        e_loss += loss.item()\n",
        "\n",
        "      if save_rate and e % save_rate == 0:\n",
        "        checkpoint = {\n",
        "            'epoch': e,\n",
        "            'data': model.chars,\n",
        "            'n_hidden': model.n_hidden,\n",
        "            'n_layers': model.n_layers,\n",
        "            'state': model.state_dict()\n",
        "        }\n",
        "        print(f'\\nSaving model at epoch {e}\\n')\n",
        "\n",
        "        with open(f'modelEpoch_{e}_{model.mode}.pth', 'wb') as f:\n",
        "          torch.save(checkpoint, f)\n",
        "\n",
        "      e_loss = e_loss / (len(encoded_valid)//(batch_size*seq_length))\n",
        "      loss_hist_valid.append(e_loss)\n",
        "\n",
        "      t = time.time() - t\n",
        "      gen_text = sample(model, topk, sample_char_size)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    print(f'Epoch {e}:')\n",
        "    print(f'Train loss: {loss_hist_train[-1]:>3.3f}')\n",
        "    print(f'Valid loss: {loss_hist_valid[-1]:>3.3f}')\n",
        "    print(f'Generated text for prefix \\'Абай\\': {gen_text}\\n')\n",
        "    print(f'Time elapsed {t/60:4.2} minutes\\n\\n')\n",
        "  \n",
        "  return loss_hist_train, loss_hist_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHqzrHq8BFPv",
        "colab_type": "text"
      },
      "source": [
        "### Helper function for plotting training results\n",
        "`plot_loss(...)` simply plots the training and validation loss scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAgniDn_smFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(loss_train, loss_valid, epochs, name, save=False):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.title(f'Loss {name}')\n",
        "  plt.plot(range(epochs), loss_train, label='Training Loss')\n",
        "  plt.plot(range(epochs), loss_valid, label='Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  if save:\n",
        "    plt.savefig(name+'.png')\n",
        "  else:\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w78twzyVIatE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(file_name, model_class):\n",
        "  \n",
        "  with open(file_name, 'rb') as f:\n",
        "    checkpoint = torch.load(f)\n",
        "  \n",
        "  loadedModel = model_class(\n",
        "    checkpoint['data'],\n",
        "    n_hidden = checkpoint['n_hidden'],\n",
        "    n_layers = checkpoint['n_layers'],\n",
        "  )\n",
        "\n",
        "  loadedModel.load_state_dict(checkpoint['state'])\n",
        "  \n",
        "  return loadedModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTvWd1M5BXn0",
        "colab_type": "text"
      },
      "source": [
        "## Training models and seeing results\n",
        "\n",
        "This is sample code for training the models, and seeing the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfwu26sgBgic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f970ba1-c8ce-4b81-ba7e-a3508180901c"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "chars = tuple(set(text))\n",
        "n_layers = 3\n",
        "n_hidden = 512\n",
        "dropout = 0.7\n",
        "lr = 0.001\n",
        "\n",
        "model = CharRNN(chars,\n",
        "                n_hidden=n_hidden, \n",
        "                n_layers=n_layers, \n",
        "                dropout=dropout,\n",
        "                mode='LSTM').to(device)\n",
        "\n",
        "printParams(model)\n",
        "\n",
        "train_loss, valid_loss = train(model, text, epochs=10, seq_length=300, \n",
        "                               batch_size=512, save_rate=None)\n",
        "\n",
        "plot_loss(train_loss, valid_loss, 10, 'LSTM')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name:    rnn.weight_ih_l0, shape:   torch.Size([2048, 112]), total params:     229376, grad params:     229376\n",
            "Name:    rnn.weight_hh_l0, shape:   torch.Size([2048, 512]), total params:    1048576, grad params:    1048576\n",
            "Name:      rnn.bias_ih_l0, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:      rnn.bias_hh_l0, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:    rnn.weight_ih_l1, shape:   torch.Size([2048, 512]), total params:    1048576, grad params:    1048576\n",
            "Name:    rnn.weight_hh_l1, shape:   torch.Size([2048, 512]), total params:    1048576, grad params:    1048576\n",
            "Name:      rnn.bias_ih_l1, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:      rnn.bias_hh_l1, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:    rnn.weight_ih_l2, shape:   torch.Size([2048, 512]), total params:    1048576, grad params:    1048576\n",
            "Name:    rnn.weight_hh_l2, shape:   torch.Size([2048, 512]), total params:    1048576, grad params:    1048576\n",
            "Name:      rnn.bias_ih_l2, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:      rnn.bias_hh_l2, shape:        torch.Size([2048]), total params:       2048, grad params:       2048\n",
            "Name:           fc.weight, shape:    torch.Size([112, 512]), total params:      57344, grad params:      57344\n",
            "Name:             fc.bias, shape:         torch.Size([112]), total params:        112, grad params:        112\n",
            "\n",
            "Total number of parameters is 5542000\n",
            "Epoch 1:\n",
            "Train loss: 4.004\n",
            "Valid loss: 3.399\n",
            "Generated text for prefix 'Абай': Абайыеаааааы    ы н ннне   н    анеаа аана енаеаны нн ын  ы     еаене  ана   ыеан еаыыаа н аыененеы наы \n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "Train loss: 3.479\n",
            "Valid loss: 3.380\n",
            "Generated text for prefix 'Абай': Абай  еаеаа  на  а аен ы ае аенные  аа   а  нныаеа ыаы еенаеыааыан  ан  нааене а  ен еан ыаы  еаыыа н еы\n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "Train loss: 3.427\n",
            "Valid loss: 3.374\n",
            "Generated text for prefix 'Абай': Абайыа аеаа аа       еа аенаены не   ыа ыаа   ан аае е  а ааа а  ен н  аныы аы  а ы аныаныааыыы еыыы  аа\n",
            "\n",
            "Time elapsed 0.54 minutes\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "Train loss: 3.407\n",
            "Valid loss: 3.370\n",
            "Generated text for prefix 'Абай': Абайн  а аа ны  е н  еае а ы а не н   еанаые ынна  ан н аыаен аые аыаыаы аеыа е на а    аа е а ыыыанааны\n",
            "\n",
            "Time elapsed 0.54 minutes\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "Train loss: 3.396\n",
            "Valid loss: 3.368\n",
            "Generated text for prefix 'Абай': Абайан   нны ыне аеаы аыыныаанеыааенн е ныыеа ыеааы е   ы анн   а ые  ыае  ееыныыаеаа ае аеа нынан  аыа \n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "Train loss: 3.391\n",
            "Valid loss: 3.367\n",
            "Generated text for prefix 'Абай': Абайн ынаан аа аыеана  еенеынеаыыыа ааы ааыан е ааееааее ы   наы ыаынне е н анн  наеа а ыееы ыааеыааеааы\n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "Train loss: 3.388\n",
            "Valid loss: 3.367\n",
            "Generated text for prefix 'Абай': Абай ы н ыеныа ан а н ыа  а аыа не а аы наы ыны еа  аеааа ыа аааен  ыы а   н наеынна  а   ен на н еаееан\n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "Train loss: 3.384\n",
            "Valid loss: 3.366\n",
            "Generated text for prefix 'Абай': Абайнаееаына ан   аа аа а еа ен ннеаыеее ыа еыы н   ыыые   е а  ыа аы  а аееыы ее анннн е еыыа аа  аны е\n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "Train loss: 3.381\n",
            "Valid loss: 3.365\n",
            "Generated text for prefix 'Абай': Абай  ааанне еын н   а ыее   ыы н  ыаеынныы аеыы н  аа   н а еы  е еа     на    еыа ыаыа еы  ы ааа аыае \n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "Train loss: 3.376\n",
            "Valid loss: 3.359\n",
            "Generated text for prefix 'Абай': Абайееыыанее нна н ыаы ннаа на аыеы е  а  ан наеаыааее анаа ыанаа   а еы не   ы аеее ы ааые наен ыны а  \n",
            "\n",
            "Time elapsed 0.55 minutes\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFNCAYAAACuWnPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C-7SWckKvdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ff722f5-a9e8-4f43-d615-debb56d2c215"
      },
      "source": [
        "n_layers = 3\n",
        "n_hidden = 512\n",
        "dropout = 0.7\n",
        "lr = 0.001\n",
        "\n",
        "model = CharRNN(chars,\n",
        "                n_hidden=n_hidden, \n",
        "                n_layers=n_layers, \n",
        "                dropout=dropout,\n",
        "                mode='GRU').to(device)\n",
        "\n",
        "printParams(model)\n",
        "\n",
        "train_loss, valid_loss = train(model, text, epochs=10, seq_length=300, \n",
        "                               batch_size=512, save_rate=None)\n",
        "\n",
        "plot_loss(train_loss, valid_loss, 10, 'GRU')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name:    rnn.weight_ih_l0, shape:   torch.Size([1536, 112]), total params:     172032, grad params:     172032\n",
            "Name:    rnn.weight_hh_l0, shape:   torch.Size([1536, 512]), total params:     786432, grad params:     786432\n",
            "Name:      rnn.bias_ih_l0, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:      rnn.bias_hh_l0, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:    rnn.weight_ih_l1, shape:   torch.Size([1536, 512]), total params:     786432, grad params:     786432\n",
            "Name:    rnn.weight_hh_l1, shape:   torch.Size([1536, 512]), total params:     786432, grad params:     786432\n",
            "Name:      rnn.bias_ih_l1, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:      rnn.bias_hh_l1, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:    rnn.weight_ih_l2, shape:   torch.Size([1536, 512]), total params:     786432, grad params:     786432\n",
            "Name:    rnn.weight_hh_l2, shape:   torch.Size([1536, 512]), total params:     786432, grad params:     786432\n",
            "Name:      rnn.bias_ih_l2, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:      rnn.bias_hh_l2, shape:        torch.Size([1536]), total params:       1536, grad params:       1536\n",
            "Name:           fc.weight, shape:    torch.Size([112, 512]), total params:      57344, grad params:      57344\n",
            "Name:             fc.bias, shape:         torch.Size([112]), total params:        112, grad params:        112\n",
            "\n",
            "Total number of parameters is 4170864\n",
            "Epoch 1:\n",
            "Train loss: 4.017\n",
            "Valid loss: 3.495\n",
            "Generated text for prefix 'Абай': Абайрнаадеадтааеаатнндададдаенедддднндддлалаееаелнннатддаенлаеннедлдлдадлдтттдеентаанннетлнледелллндатдд\n",
            "\n",
            "Time elapsed 0.46 minutes\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "Train loss: 3.533\n",
            "Valid loss: 3.406\n",
            "Generated text for prefix 'Абай': Абайнннаеыа ы  аееа ааааееыае   е еыа ыа н ааа    н еааы е ан аны аын  еые аыаыаен аыаа а  ен   ы  ееа  \n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "Train loss: 3.446\n",
            "Valid loss: 3.374\n",
            "Generated text for prefix 'Абай': Абайнааены н    ы аны    ааа а а  ы  н н еынен еанн  а ныеыаа ааананнееааыны  аы аа  аыааа нынаныаыее   \n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "Train loss: 3.405\n",
            "Valid loss: 3.339\n",
            "Generated text for prefix 'Абай': Абай аеененна ы   аынаа нае  еа аыаннаае наыаы  а е   ыааааыеаеаа  аеееаы е  аеее аеаеаееа ны еененны ыы\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "Train loss: 3.350\n",
            "Valid loss: 3.271\n",
            "Generated text for prefix 'Абай': Абай аынаанееа ыааыа  анаеаы ааеыаан   ы на  а ы ыа е нныа ныын  ааа ааын  ыаыын н  ныы аеаеы е ннее  ее\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "Train loss: 3.238\n",
            "Valid loss: 3.079\n",
            "Generated text for prefix 'Абай': Абайа ааыан  баааыыаы  браныаа  атна  арлнн  ааын \n",
            "оеаы аеаыан  аааыыын  еааыр  браы быан  өрааыы быаынн\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "Train loss: 3.033\n",
            "Valid loss: 2.822\n",
            "Generated text for prefix 'Абай': Абай жаырын қырааы қалын алра аллаыыы аараыы жылн күе кее \n",
            "өеі ееiе жетрен борны жаыраранн қалтррта алта\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "Train loss: 2.795\n",
            "Valid loss: 2.584\n",
            "Generated text for prefix 'Абай': Абайн аа аы жарды құағы.\n",
            "\n",
            "Бүрантттең бұлартап жара қаланы болалтап жоларда аанын қой арттын бұылы қала ж\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "Train loss: 2.597\n",
            "Valid loss: 2.450\n",
            "Generated text for prefix 'Абай': Абайынаны беле кел кері күрiп жаралан жарын жартыр ардай анандан,.\n",
            "\n",
            "Осын жейе дай белірда дұсы тырана жа\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "Train loss: 2.485\n",
            "Valid loss: 2.387\n",
            "Generated text for prefix 'Абай': Абайаңда жарылы қойғы тұна күйiнi болы тылыны жақ тартын құнанар қалтана қарғып алы бар жанын жыларап ай\n",
            "\n",
            "Time elapsed 0.45 minutes\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFNCAYAAACuWnPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl4VNX9x/H3yR6yEkKAsIVFIOxL\nUHYEBBEVi1p3q9aColVcK7W2tf7Uat1wA7UurYpbtVQFFBFRQBAJ+6psYUtYEkgIWch2fn/cYYsB\nAmRyZ5LP63nmyczcO3e+AVs/nnPu9xhrLSIiIiLingC3CxARERGp7RTIRERERFymQCYiIiLiMgUy\nEREREZcpkImIiIi4TIFMRERExGUKZCIiIiIuUyATEZ9ljEkzxpzn0nc3Msb80xiTbow5YIzZZIz5\nlzGmned4kjHGeo4d8NQ6vtw1rDGmdbn3HjbGvFudv4uI+D4FMhGRcowx9YD5QB2gPxAFdAe+A4aW\nOz3WWhsJXA782RhT/riIyEkpkImIXzLGjDbGbDDG7DXGfGaMSfS8b4wxzxljdhtj9htjVhpjOnqO\njTDGrDHG5Bpjdhhj7jvO5e8G9gPXW2s3Wke2tfYta+2LFX3AWpsKrAa6euHXFZEaToFMRPyOMWYw\n8HfgCqARsAX4wHN4GDAAaAPEeM7J8hx7A7jFWhsFdAS+Oc5XnAdMsdaWnUJNvTzX3HBKv4yICApk\nIuKfrgXetNYusdYeBP4I9DbGJAHFOFOM7QBjrV1rrc3wfK4YaG+MibbW7rPWLjnO9eOBnYdeGGNG\nGmOyPSNrX5U7N9MYUwAsACYC/6ui31FEahEFMhHxR4k4o2IAWGsP4IyCNbbWfgO8BLwM7DbGvGaM\nifacehkwAthijPnOGNP7ONfPwhl5O3T9z6y1sThTmSHlzo0HIoF7gXOB4KOOlZZ7jed1cSV/TxGp\nJRTIRMQfpQPND70wxkQA9YAdANbaF6y1PYD2OFOX93veX2StvQRIwBnJ+ug4158F/MoYU6n/j7TW\nllprnwUKgduOOrQVSCp3eguOCpMiIqBAJiK+L9gYE3bUIwh4H7jJGNPVGBMKPA4stNamGWN6GmPO\nMcYEA3k4IanMGBNijLnWGBNjrS3GWbR/vDVizwJ1gXeMMa08NwpEcfIF+08AfzDGhHlefwg8ZIxp\nYowJ8LTwuBj4+Az+PESkBlIgExFfNx0oOOrxsLX2a+DPwCdABtAKuMpzfjTwT2AfzkhUFvCU59j1\nQJoxZj9wK85atF+w1mYCvXDC3DwgF1iGszZt7Alqneb53tGe14/gtM+Y53n/H8C11tpVlf7tRaRW\nMNZat2sQERERqdU0QiYiIiLiMgUyEREREZcpkImIiIi4TIFMRERExGUKZCIiIiIuC3K7gFMVHx9v\nk5KS3C5DRERE5KQWL16caa2tf7Lz/C6QJSUlkZqa6nYZIiIiIidljKnUzhyashQRERFxmQKZiIiI\niMsUyERERERc5ndryERERGqy4uJitm/fTmFhodulyCkICwujSZMmBAcHn9bnFchERER8yPbt24mK\niiIpKQljjNvlSCVYa8nKymL79u20aNHitK6hKUsREREfUlhYSL169RTG/Igxhnr16p3RqKYCmYiI\niI9RGPM/Z/p3pkAmIiIih2VlZdG1a1e6du1Kw4YNady48eHXRUVFlbrGTTfdxE8//XTCc15++WUm\nT55cFSXTr18/li1bViXXcovWkImIiMhh9erVOxxuHn74YSIjI7nvvvuOOcdai7WWgICKx3Xeeuut\nk37P7bfffubF1iBeHyEzxgQaY5YaY6ZWcCzUGPOhMWaDMWahMSbJ2/WcTHFpGa/N2UhBUanbpYiI\niPiMDRs20L59e6699lo6dOhARkYGY8aMISUlhQ4dOvDII48cPvfQiFVJSQmxsbGMHz+eLl260Lt3\nb3bv3g3AQw89xIQJEw6fP378eM4++2zatm3L/PnzAcjLy+Oyyy6jffv2XH755aSkpFR6JKygoIAb\nbriBTp060b17d+bMmQPAypUr6dmzJ127dqVz585s2rSJ3NxcLrjgArp06ULHjh35+OOPq/KPrlKq\nY8pyHLD2OMduBvZZa1sDzwFPVkM9J7RsWzZ//2Idf/50FdZat8sRERHxGevWrePuu+9mzZo1NG7c\nmCeeeILU1FSWL1/OzJkzWbNmzS8+k5OTw8CBA1m+fDm9e/fmzTffrPDa1lp+/PFHnnrqqcPh7sUX\nX6Rhw4asWbOGP//5zyxdurTStb7wwguEhoaycuVK3nnnHa6//nqKioqYOHEi9913H8uWLWPRokUk\nJiYyffp0kpKSWL58OatWrWLo0KGn9wd0Brw6ZWmMaQJcCDwG3FPBKZcAD3uefwy8ZIwx1sUk1DMp\njjsGn8ULs9aT0rwuV53dzK1SRESklvvb56tZk76/Sq/ZPjGav17c4bQ+26pVK1JSUg6/fv/993nj\njTcoKSkhPT2dNWvW0L59+2M+Ex4ezgUXXABAjx49mDt3boXXvvTSSw+fk5aWBsC8efN44IEHAOjS\npQsdOlS+7nnz5nH//fcD0KFDBxITE9mwYQN9+vTh0UcfZcuWLVx66aW0bt2azp07M378eMaPH8/F\nF19M3759K/09VcXbI2QTgD8AZcc53hjYBmCtLQFygHperumkxg05i/5nxfOXz1azakeO2+WIiIj4\nhIiIiMPP169fz/PPP88333zDihUrGD58eIVtH0JCQg4/DwwMpKSkpMJrh4aGnvScqnD99dczZcoU\nQkNDGT58OHPmzCE5OZnU1FQ6dOjA+PHjefzxx732/cfjtREyY8xFwG5r7WJjzLlneK0xwBiAZs28\nP2IVGGCYcGVXLnpxHrdNXsLnd/QjJvz0Ou+KiIicrtMdyaoO+/fvJyoqiujoaDIyMpgxYwbDhw+v\n0u/o27cvH330Ef3792flypUVTokeT//+/Zk8eTIDBgxg7dq1ZGRk0Lp1azZt2kTr1q0ZN24cmzdv\nZsWKFbRq1Yr4+Hiuv/56oqKiePfdd6v096gMb05Z9gVGGmNGAGFAtDHmXWvtdUedswNoCmw3xgQB\nMUBW+QtZa18DXgNISUmplunMepGhvHRNd658dQH3frSc167vQUCA+sKIiIgAdO/enfbt29OuXTua\nN2/ulWm+O+64g9/85je0b9/+8CMmJqbCc88///zD2xb179+fN998k1tuuYVOnToRHBzM22+/TUhI\nCO+99x7vv/8+wcHBJCYm8vDDDzN//nzGjx9PQEAAISEhvPLKK1X+u5yMqY7lWp4RsvustReVe/92\noJO19lZjzFXApdbaK050rZSUFJuamuq9Yst5c95mHpm6hvEXtOPWga2q7XtFRKR2Wrt2LcnJyW6X\n4RNKSkooKSkhLCyM9evXM2zYMNavX09QkG927aro784Ys9ham3KcjxxW7b+RMeYRINVa+xnwBvCO\nMWYDsBe4qrrrOZmb+iaxeOs+/vHlOro2jaVXS9eXuImIiNQKBw4cYMiQIZSUlGCt5dVXX/XZMHam\nquW3stZ+C3zref6Xo94vBH5dHTWcLmMMT17WmbUZ+/n9e0uZfmc/EqLD3C5LRESkxouNjWXx4sVu\nl1EttHVSJUSGBjHp2h7kHSzh9+8vpaT0eDeNioiIiJw6BbJKatswiscv7ciPm/fy1Fcn3p9LRERE\n5FQokJ2CUd2acO05zXj1u018tXqn2+WIiIhIDaFAdor+fFF7OjWO4d7/LGdLVp7b5YiIiEgNoEB2\nisKCA5l4bXcCjGHsu0soLNYm5CIiUnMMGjSIGTNmHPPehAkTGDt27Ak/FxkZCUB6ejqXX355heec\ne+65nKx11YQJE8jPzz/8esSIEWRnZ1em9BN6+OGHefrpp8/4Ot6iQHYamsbV4bkru7AmYz8Pf7ba\n7XJERESqzNVXX80HH3xwzHsffPABV199daU+n5iYyMcff3za318+kE2fPp3Y2NjTvp6/UCA7TYPb\nNeD2Qa34YNE2/pO6ze1yREREqsTll1/OtGnTKCoqAiAtLY309HT69+9/uC9Y9+7d6dSpE59++ukv\nPp+WlkbHjh0BKCgo4KqrriI5OZlRo0ZRUFBw+LyxY8eSkpJChw4d+Otf/wrACy+8QHp6OoMGDWLQ\noEEAJCUlkZmZCcCzzz5Lx44d6dixIxMmTDj8fcnJyYwePZoOHTowbNiwY77nZCq6Zl5eHhdeeCFd\nunShY8eOfPjhhwCMHz+e9u3b07lzZ+67775T+nM9mZrZXa2a3DO0LUu3ZvPQ/1bRITGG9onRbpck\nIiJyRuLi4jj77LP54osvuOSSS/jggw+44oorMMYQFhbGlClTiI6OJjMzk169ejFy5EiMqXhrwUmT\nJlGnTh3Wrl3LihUr6N69++Fjjz32GHFxcZSWljJkyBBWrFjBnXfeybPPPsvs2bOJj48/5lqLFy/m\nrbfeYuHChVhrOeeccxg4cCB169Zl/fr1vP/++/zzn//kiiuu4JNPPuG6664rX84vHO+amzZtIjEx\nkWnTpgGQk5NDVlYWU6ZMYd26dRhjqmQa9WgKZGcgMMDw/FXduPCFudw2eTGf3dGP6DBtQi4iIlXk\ni/Gwc2XVXrNhJ7jgiROecmja8lAge+ONNwCw1vLggw8yZ84cAgIC2LFjB7t27aJhw4YVXmfOnDnc\neeedAHTu3JnOnTsfPvbRRx/x2muvUVJSQkZGBmvWrDnmeHnz5s1j1KhRREREAHDppZcyd+5cRo4c\nSYsWLejatSsAPXr0IC0trVJ/FMe75vDhw7n33nt54IEHuOiii+jfv//hLZxuvvlmLrroIi666KKT\nXP3UaMryDNWPCuXla7uzbV8Bf/jPCqpjb1ARERFvuuSSS5g1axZLliwhPz+fHj16ADB58mT27NnD\n4sWLWbZsGQ0aNKCwsPCUr79582aefvppZs2axYoVK7jwwgtP6zqHhIaGHn4eGBhISUnJaV8LoE2b\nNixZsoROnTrx0EMP8cgjjxAUFMSPP/7I5ZdfztSpUxk+fPgZfUd5GiGrAj2T4vjjBe14dNpaXp+7\nmdEDWrpdkoiI1AQnGcnylsjISAYNGsRvf/vbYxbz5+TkkJCQQHBwMLNnz2bLli0nvM6AAQN47733\nGDx4MKtWrWLFihUA7N+/n4iICGJiYti1axdffPEF5557LgBRUVHk5ub+Ysqyf//+3HjjjYwfPx5r\nLVOmTOGdd945o9/zeNdMT08nLi6O6667jtjYWF5//XUOHDhAfn4+I0aMoG/fvrRsWbX/rlcgqyI3\n92tBato+nvhyHV2bxdIzKc7tkkRERE7b1VdfzahRo4654/Laa6/l4osvplOnTqSkpNCuXbsTXmPs\n2LHcdNNNJCcnk5ycfHikrUuXLnTr1o127drRtGlT+vbte/gzY8aMYfjw4SQmJjJ79uzD73fv3p0b\nb7yRs88+G4Df/e53dOvWrdLTkwCPPvro4YX7ANu3b6/wmjNmzOD+++8nICCA4OBgJk2aRG5uLpdc\ncgmFhYVYa3n22Wcr/b2VYfxtii0lJcWerIeJW/YXFjPyxXnkF5Uy7c7+1I8KPfmHREREjrJ27VqS\nk5PdLkNOQ0V/d8aYxdbalJN9VmvIqlB0WDCTrutBTkExd2oTchEREakkBbIqltwomkd/1ZEFm7J4\n7uuf3S5HRERE/IACmRf8OqUpV/VsysuzNzJr7S63yxEREREfp0DmJQ+P7ECHxGju/nAZ2/bmn/wD\nIiIiHv62vlvO/O9MgcxLwoIDmXRtDywwdvJibUIuIiKVEhYWRlZWlkKZH7HWkpWVRVhY2GlfQ20v\nvKhZvTo8e0VXRr+dyiNT1/D4qE5ulyQiIj6uSZMmbN++nT179rhdipyCsLAwmjRpctqfVyDzsqHt\nG3DrwFa88t1GUprX5dLup/+XJSIiNV9wcDAtWrRwuwypZpqyrAb3DWvDOS3ieHDKStbt3O92OSIi\nIuJjvBbIjDFhxpgfjTHLjTGrjTF/q+CcZsaY2caYpcaYFcaYEd6qx01BgQG8eE03osKCue3dJeQW\nFrtdkoiIiPgQb46QHQQGW2u7AF2B4caYXuXOeQj4yFrbDbgKmOjFelyVEBXGi1d3Y8vefB74RJuQ\ni4iIyBFeC2TWccDzMtjzKJ9CLBDteR4DpHurHl/Qq2U97j+/LdNX7uSt79PcLkdERER8hFfXkBlj\nAo0xy4DdwExr7cJypzwMXGeM2Q5MB+7wZj2+4JYBLRnavgGPT1/L4i173S5HREREfIBXA5m1ttRa\n2xVoApxtjOlY7pSrgX9Za5sAI4B3jDG/qMkYM8YYk2qMSfX324CNMTz96y4kxoZz++SlZB046HZJ\nIiIi4rJqucvSWpsNzAaGlzt0M/CR55wFQBgQX8HnX7PWplhrU+rXr+/tcr0uJjyYidd2Z29+EeM+\nWEZpmdaTiYiI1GbevMuyvjEm1vM8HBgKrCt32lZgiOecZJxA5t9DYJXUsXEM/3dJB+ZtyOR5bUIu\nIiJSq3lzhKwRMNsYswJYhLOGbKox5hFjzEjPOfcCo40xy4H3gRttLbr98IqUplzeowkvfLOB2T/t\ndrscERERcYnxt/yTkpJiU1NT3S6jyhQUlTJq4vfs3F/I1Dv60aRuHbdLEhERkSpijFlsrU052Xnq\n1O+y8JBAJl3Xg9JSy+2Tl3CwRJuQi4iI1DYKZD6gRXwET/26M8u35/DYtLVulyMiIiLVTIHMRwzv\n2IjR/Vvw9oItfLpsh9vliIiISDVSIPMhfxjejp5JdRn/yUrW78p1uxwRERGpJgpkPiQ4MICXrulO\nRGggt767mLyDJW6XJCIiItVAgczHNIgO44Wru7E5M4/x/12pTchFRERqAQUyH9SnVTz3DmvL58vT\neXvBFrfLERERES9TIPNRYwe2Yki7BB6dtoalW/e5XY6IiIh4kQKZjwoIMDxzRRcaRIdx++Ql7M0r\ncrskERER8RIFMh8WWyeEidd2J/NAEXd9qE3IRUREaioFMh/XuUksfx3Znjk/7+Glbza4XY6IiIh4\ngQKZH7jm7GZc2q0xE2b9zJyf97hdjoiIiFQxBTI/YIzh0VEdOSshknEfLCU9u8DtkkRERKQKKZD5\niTohQUy6rgfFpZbb31tCUUmZ2yWJiIhIFVEg8yOt6kfy5GWdWbo1m8enaxNyERGRmkKBzM9c2LkR\nN/VN4l/z0/h8ebrb5YiIiEgVUCDzQ3+8IJnuzWIZ/8kKNuw+4HY5IiIicoYUyPxQSFAAL1/bndDg\nQG6bvJj8Im1CLiIi4s8UyPxUo5hwnr+qK+t3H+BBbUIuIiLi1xTI/Fj/s+pz93lt+N+ydCYv3Op2\nOSIiInKaFMj83O8HtWZgm/o88vkaVmzPdrscEREROQ0KZH4uIMAw4cqu1I8KZey7S8jO1ybkIiIi\n/sZrgcwYE2aM+dEYs9wYs9oY87fjnHeFMWaN55z3vFVPTVY3IoSXr+3O7txC7v5wGWXahFxERMSv\neHOE7CAw2FrbBegKDDfG9Dr6BGPMWcAfgb7W2g7AXV6sp0br2jSWP1/Untk/7WHit9qEXERExJ94\nLZBZx6EmWcGeR/mhm9HAy9bafZ7P7PZWPbXB9b2aM7JLIs/O/JnvN2S6XY6IiIhUklfXkBljAo0x\ny4DdwExr7cJyp7QB2hhjvjfG/GCMGe7Nemo6Ywx/v7QTLetHcuf7S9mZU+h2SSIiIlIJXg1k1tpS\na21XoAlwtjGmY7lTgoCzgHOBq4F/GmNiy1/HGDPGGJNqjEnds2ePN0v2exGhQbxyXXcKikv5/XtL\nKC7VJuQiIiK+rlrusrTWZgOzgfIjYNuBz6y1xdbazcDPOAGt/Odfs9amWGtT6tev7/2C/VzrhCie\nuKwzqVv28eQX69wuR0RERE7Cm3dZ1j802mWMCQeGAuXTwf9wRscwxsTjTGFu8lZNtcnILonc0Ls5\nr8/bzBcrM9wuR0RERE7AmyNkjYDZxpgVwCKcNWRTjTGPGGNGes6ZAWQZY9bgjKDdb63N8mJNtcqD\nFybTpWks93+8gk17tAm5iIiIrzL+tgdiSkqKTU1NdbsMv7Eju4ALX5hLw+gwptzWl/CQQLdLEhER\nqTWMMYuttSknO0+d+mu4xrHhTLiyKz/tyuWh/63SJuQiIiI+SIGsFji3bQJ3DD6LT5Zs54NF29wu\nR0RERMpRIKslxg05i/5nxfPXz1azakeO2+WIiIjIURTIaolAzybk9SJCGDt5MTn5xW6XJCIiIh4K\nZLVIvchQXrqmOxnZhQx+5ltueSeV1+duYtm2bDWQFRERcVGQ2wVI9erRvC5v3tiT/y3dwaIte5mx\nehcAYcEBdG0aS0rzOFKS6tK9eV2iw4JdrlZERKR2UNuLWm7X/kJS0/aRumUvqWn7WJOxn9IyizHQ\ntkEUPZOcgJaSFEfj2HC3yxUREfErlW17oUAmx8g7WMKybdksStvL4i37WLJlH3lFpQAkxoTRIymO\nnkl16dG8Lu0aRhMYYFyuWERExHdVNpBpylKOEREaRN/W8fRtHQ9ASWkZ63bmkpq2l0Vb9vHj5iw+\nX54OQGRoEN2b1yWleV1SkurStWksdUL0j5SIiMip0ghZeaXFsOFraHoO1Inz3vf4KWst2/cVHJ7i\nTE3bx8+7c7EWggIMHRKjSUmKI6V5XXok1SUhKsztkkVERFyjKcvTtT0VXh/iPE9oD816QbM+0Lw3\nxDTx3vf6sZz8YpZs3ceitL2kbtnH8m3ZHCxx7tpsXq8OKc2dac6UpLq0qh+JMZrmFBGR2kGB7HQV\nF8KOVNiyALYugG0/QlGucyymmRPQmvd2Qlr9tqBw8QtFJWWsSs9xpjnT9rF4yz725hUBULdOMD2a\nOzcJ9EyqS8fGMYQGaX9NERGpmRTIqkppCexa5YSzLfOdn3l7nGPhcdCstyek9YFGXSBQrSLKs9ay\nKTOPxWlHRtE2Z+YBEBIUQJcmMfRofuRmgdg6IS5XLCIiUjUUyLzFWti76Ug427rAeQ0QXAeapHhC\nWm9o0hNCI92r1YdlHjhIato+Fm9xRtFW7cihpMz5Z/GshMjD69B6JsXRNC5c05wiIuKXFMiqU+5O\nzwjaAtg6H3auAiyYQGfUrFlvzzRnb4iId7tan1RQVMry7dmkekbQFm/ZR25hCQAJUaFOLzRP09r2\njaIJCtQmEyIi4vsUyNxUmAPbFjnhbOsPzo0CpQedY/Ftjr1RILa51qFVoLTM8vOuXFK37HNCWto+\ndmQXAFAnJNDZVcCzDq1bs7pEhqrdhoiI+B4FMl9SchDSl3qmOX+AbT84oQ0gKvHI6Fmz3s6dnQEa\n/alIRk6Bp9WGM825bud+yiwEGEhuFO3phxZHz6Q4Gsao3YaIiLhPgcyXlZXB7jXH3iiQm+EcC4uB\npr2O3CiQ2A2CQt2t10flFhazdGv24VG0pVuzKSh2dhVoEB1K49hwGsWG0yg6zPkZE+Z5hFM/KlS7\nDIiIiNcpkPkTayF7y5E1aFt/gMyfnWNBYdC4x5FpzqZnQ1i0u/X6qOLSMtZm7GdR2j5Wp+eQkV3I\nzv2FpGcXHO6LdkhQgKFBdBgND4c0J6g1ijkS3uIjFdpEROTMKJD5u7zMo24UWAAZy8GWggmABh2P\nulGgD0Q1cLtan2atJTu/mPScAnbmFJKeU8jOnAIysgsPv5eRU3jc0HZ0SCsf3uIjQwlQaBMRkeNQ\nIKtpDh6A7YuOtNrYtghKnEXuxLV0gtmhac64lrpR4BRZa9mXX0x69qGAVkCGJ6gd/bzoOKEtMTaM\nhjHhJHoCW8OYcM97YcRHKLSJiNRWrgcyY0wYMAcIxdnE/GNr7V+Pc+5lwMdAT2vtCdNWrQ1k5ZUW\nO6Nmh24U2LoACvY6xyISjr1RoGEnCFA3/DNlrWVvXtEvg1r2kcC2M6eQotJjQ1twoCe0xYQ7U6Sx\nYeXWtYVTLyJEoU1EpAbyhUBmgAhr7QFjTDAwDxhnrf2h3HlRwDQgBPi9AtlpKitz1p1tne+Z5vwB\ncrY6x0KinLVnh6Y5G/eA4HB3662hrLVk5RU5U6PZBZ41bM4UabonxO3MKaS49Nj/3YUEBtAgJvTI\nOraYY29CaBQbRr2IEDXIFRHxM5UNZF5r3mSdpHfA8zLY86go/f0f8CRwv7dqqRUCAiChnfNI+a3z\nXs72Y28UmP2o59xgiGvhjKRFxENEfc/j6Oee12Exmv48BcYY4iNDiY8MpWPjmArPKSs7KrQdXtfm\nmSrNLmTJ1n3szMmoMLQdfRNC83oRtIh3HknxEcSEa9suERF/5dVumsaYQGAx0Bp42Vq7sNzx7kBT\na+00Y4wCWVWLaQKdf+08APL3wraFnu2eNjs3Duxa7ezNWZhd8TUCgo8Na5HlQ9xRx+rEQ7D6f51M\nQIChflQo9aNC6dTkxKGtomnRjJwCFqXt49Pl6Rw9wB0fGULSoZBWP4IW9ZyfSfUiCAvWlLWIiC+r\nlkX9xphYYApwh7V2lee9AOAb4EZrbZox5lvgvoqmLI0xY4AxAM2aNeuxZcsWr9dc65QUQX6WE87y\n9jhh7bjPd0NJYcXXCY2uYNQtoeIRuPC6aoJ7BgqLS9m2N59NmXmkZeaxOTPv8PPduQePObdxbDhJ\n8XU8I2qRtIivQ4v4SJrUDSdY21CJiHiN62vIfvFFxvwFyLfWPu15HQNs5Mi0ZkNgLzDyROvItIbM\nB1gLRXlOMDsmrB0nyOVngS375XVMgDOq9ouwdvRo3FGvQyKq/3f1UwcOlpB2VEA7FNY27znAfs8e\noeDcJdosrg5J8UemPw89GkaH6UYDEZEz5PoaMmNMfaDYWpttjAkHhuKsFQPAWpsDxB91/rccZ4RM\nfIwxEBrpPOJanvz8slIo2Hf84HbA83PHYuf9otyKrxNc5+Rr3iLqOyNydepBYO3d3zIyNIiOjWN+\nsY7tUHuPzZkH2LQnj7QsT1jbk8f8jZkUFh8JzmHBAUemQMs94nSDgYhIlfLmv7EaAf/2rCMLAD6y\n1k41xjwCpFprP/Pid4svCQj0hKV4IPnk5xcXHBXYjjMCtz8dMlY4z8uKK7iIcUJZZAOncW5kA2fE\nLbKh52cDiPI8D42uNTcuGGOMaXj1AAAgAElEQVSIiwghLiKOHs3jjjlWVmbZlVvI5j3Hjqz9tDOX\nmWt2UVJ2ZDQ9OizoqIAWeXjNWlJ8HaLCdHOBiMipUmNY8W/WOhu1Hw5uu4+Muh3YBQd2e356HqVF\nv7xGUPiRkBaZ4AlqFQS4yAQIrJ1ho6S0jO37Co5Zp7bZ80jPKTjm5oL6UaHODQWHbi7wBLdmcXV0\nc4GI1Do+t4asqiiQyWmz1rmbNHfXUWFt55HnuTuPBLhDTXbLOzTqFtngxAGuFrULKSwuZUtWvjMN\nWi6sZR44EoCNcW4uOHrqMyk+gpbxETSODSdINxeISA3k+hoyEZ9jjHNnZ3hdp1/biZQUOaNtB3ZV\nEOA872/d6BwrPfjLzweFHTWyVlGA8xyLSICgEO/8vtUkLDiQtg2jaNsw6hfH9hcWHxPQDj2mLNlB\n7sEjNxcEBzo3Fxw9DdqpcQwdEqN1Y4GI1AoaIRM5E4emTMuHtaNH2w498rMqvkZ4XAVr3RqUW+/W\nAMJia8yo26EdDTZn5rF5Tx6bszw/M53nh/YMTYgKZUhyAkPaNaBv63jCQzTlKSL+RVOWIr6mtPio\nkHaSAFdRn7fAkCMjbVENIf4saNDR2au0Xusas19pWZklPaeAhZv2MmvdLub8nMmBgyWEBgXQr3U8\nQ5IbMCQ5gQbRakIsIr5PgUzEX1kLB/cfta6tgpsT9mdA1oYjd5gGhUNCMjTsCA06eX52cNay+bmi\nkjIWbs5i1trdfL12F9v3FQDQqXEMQ5ITOC+5AR0So9WGQ0R8kgKZSE1XUgSZP8HOVbBrFexc6fw8\nemo0tpknoB0KaR0htrnf7pBgreXnXQf4eu0uZq3dxdJt2VgLDaPDGJycwHnJCfRpFa+7OUXEZyiQ\nidRG1kJuhiekrTwS1rI2HNktISTKGT07FNAadnZG10LquFv7acg8cJDZ63Yza+1u5q7fQ15RKeHB\ngfRtHc95yQkMTk4gIUpTmyLiHgUyETmiKB92rz02pO1cdWRXBBMAca2OCmmdnJ/RiX5zI8HBklJ+\n2LSXWWt3MWvtbnZkO1ObXZrEHF531r6RpjZFpHopkInIiVkL2Vucqc6jpz2ztxw5Jzyu3Lq0jlC/\nnc+36rDWsm5nLrPW7uLrtbtZvt2Z2kyMcaY2hyQ3oHfLepraFBGvUyATkdNTmAO71ngC2gonrO1e\nCyXOiBMBQRDf1gloh0bSGnbybI3lm/bkOlObX6/dxdz1mRQUl1InJJB+reM5L7kBg9olUD8q1O0y\nRaQGUiATkapTVgpZG49MeR66gSA348g5kQ1/OeVZr7XPbfJeWFzKgk1Zh6c2M3IKMQa6NInlPM/o\nWbuGUZraFJEqoUAmIt6Xl/XLdWl71h3VjiPMuWHg6JDWoAOEx7pbt4e1ljUZ+5m1djez1u5i+fYc\nwNniaYgnnPVqGUdokKY2ReT0KJCJiDsq044jplm5Kc+OEJvkejuO3fsL+Wbdbr5eu5t5G/ZQWFxG\nREgg/c+qz5DkBAa3S6BepKY2RaTyFMhExHdY6zS53bnyBO04Ip3Rs0MBrcVAqNfKtZILi0uZvzGT\nrz2jZ7v2H8QY6NY0liHJDTgvuQFtGkRqalNETkiBTER8X1E+7Fl77Lq0XaudnQpMAHS5Ggb+Aeom\nuVqmtZZVO/Y7DWnX7WLVjv0ANI0LZ0g7p6XGOS3qERLknw13RcR7FMhExD9ZC/s2w4+vw6LXwZZC\n999A//sgprHb1QGwM6eQWeucmwK+35DJwZIyIkODGNAmniHtnLs24yJ8uzWIiFSPKg1kxphWwHZr\n7UFjzLlAZ+Bta232GVd6ihTIRGqR/ekw52lY8rYzYtbzZuh3N0QmuF3ZYQVFpczbkOnctbluN3ty\nDxJgoHuzup6pzQRaJ2hqU6S2qupAtgxIAZKA6cCnQAdr7YgzrPOUKZCJ1EL70uC7p2D5e86dm+fc\nAn3uhDpxbld2jLIyy8odOYcb0q7JcKY2m8XV4TxPOOvZIo7gQE1titQWVR3Illhruxtj7gcKrbUv\nGmOWWmu7VUWxp0KBTKQWy1wP3z4Bqz6B0Cjo/XvoNRbCot2urELp2QXMWufcFDB/YxZFJWVEhQUx\nsE19hnVoyIiODQlSOBOp0ao6kC0EJgB/Ai621m42xqyy1nY881JPjQKZiLBrNcx+HNZNhfC60Hcc\nnD0GQiLcruy48otKmLvemdr8Zt0eMg8cpHVCJA+OaMegtgma0hSpoao6kLUHbgUWWGvfN8a0AK6w\n1j555qWeGgUyETlsxxInmG2YCREJ0P9e6HEjBIe5XdkJlZVZvlqziye/XMfmzDz6tKrHgyOS6dg4\nxu3SRKSKee0uS2NMXaCptXbFSc4LA+YAoUAQ8LG19q/lzrkH+B1QAuwBfmut3VL+WkdTIBORX9j6\nA3zzKKTNhejGMOB+6HYdBAa7XdkJFZeW8d7CrUz4+mf25RdzabfG3Ht+WxrHhrtdmohUkaoeIfsW\nGIkTrBYDu4HvrbX3nOAzBoiw1h4wxgQD84Bx1tofjjpnELDQWptvjBkLnGutvfJEtSiQiUiFrIXN\n3znBbPsip3fZwPHQ+QoI8O2tj/YXFjNx9kbe/H4zADf3a8HYc1sRHebbgVJETq6ygayyq0ljrLX7\ngUtx2l2cA5x3og9YxwHPy2DPw5Y7Z7a1Nt/z8gegSSXrERE5ljHQ8ly4eSZc8x8IjYb/3QoTe8Gq\n/0JZmdsVHld0WDDjL2jHN/cO5MJOjZj07UbOfepb3l6QRnGp79YtIlWnsoEsyBjTCLgCmFrZixtj\nAj0tM3YDM621C09w+s3AF5W9tohIhYyBNsNgzHdwhad/2cc3wav9Yd10ZyTNRzWpW4fnruzK57/v\nR9sGUfzl09Wc/9wcZqzeib818RaRU1PZQPYIMAPYaK1dZIxpCaw/2YestaXW2q44I19nG2MqvCvT\nGHMdTp+zp45zfIwxJtUYk7pnz55KliwitVpAALS/BMbOh0v/CcX58MHV8M/BsGGWTwezTk1ieG/0\nObx5YwoBAYZb3lnMFa8uYNm2au/FLSLVpNq2TjLG/AXIt9Y+Xe7984AXgYHW2t0nu47WkInIaSkt\nhuXvw3f/gJxt0KwPDH4Ikvq6XdkJlZSW8WHqNp6b+TOZB4q4uEsifzi/LU3j6rhdmohUQpWuITPG\nNDHGTDHG7PY8PjHGnHC9lzGmvjEm1vM8HBgKrCt3TjfgVWBkZcKYiMhpCwx29sS8YzGMeBr2boR/\njYB3RsH2xW5Xd1xBgQFce05zvr1/EHcObs3MNTsZ8sx3PDZtDTn5xW6XJyJVpLJ3Wc4E3gPe8bx1\nHXCttXboCT7TGfg3EIgT/D6y1j5ijHkESLXWfmaM+RroBGR4PrbVWjvyRLVohExEqkRRPqS+AfOe\ng/wsaDsCBj0IDTu5XdkJ7cwp5NmZP/GfxduJDgvmjsGtub53c0KDfPtOUpHaqsr3svSsBTvhe9VB\ngUxEqtTBXFj4Cnz/IhzMgQ6j4Nw/Qv22bld2QmvS9/P3L9Yyd30mzeLq8MDwdozo1FAd/0V8TFW3\nvcgyxlznuWsy0LMIP+vMShQR8QGhUU4j2buWOz/Xz3RaZUy5FfZudru642qfGM07N5/Dv397NnVC\nArn9vSVcOmk+qWl73S5NRE5DZUfImuMsvO+N00tsPnCHtXabd8v7JY2QiYhX5WXC9xPgx39CWYnT\n8X/A/RDju20SS8ssnyzezjMzf2LX/oMM79CQBy5oR4t4393bU6S28NrWSUd9wV3W2gmn9eEzoEAm\nItUidyfMfQZS33J6m6X8FvrdA1EN3K7suPKLSnh97mZe+W4jRSVlXNerOXcOOYu4iBC3SxOptaoj\nkG211jY7rQ+fAQUyEalW2VthzlOwdDIEhcLZo6HvXVAnzu3Kjmt3biETvl7PBz9uJSI0iNsHtebG\nPkmEBWvhv0h1q45Ats1a2/S0PnwGFMhExBVZG+G7J2HFRxASCb1vg963Q1iM25Ud1/pduTzxxTpm\nrdtN49hw7j+/LSO7JBIQoIX/ItVFI2QiIt6wey18+3dY8ymExULfcXDOLRDiu+u15m/I5LHpa1md\nvp9OjWN4cEQyvVvVc7sskVqhSgKZMSaXchuCHzoEhFtrg06/xNOjQCYiPiF9Gcx+HNbPgIj6zvqy\nlN9CcJjblVWorMzy6fIdPPXlT6TnFHJecgLjL2hH64Qot0sTqdG8PkLmFgUyEfEp236Ebx6Fzd9B\nVCIMuA+6XQ9BvrmQvrC4lDe/38yk2RvJLy7lqp5Nueu8NtSPCnW7NJEaSYFMRKQ6bZ4D3zwG236A\n2GYwcDx0vhICq30ioVKyDhzkhVnrmbxwK6FBAYw9txU392tJeIgW/otUJQUyEZHqZi1smAXf/B9k\nLIN6rZ2u/x0uhYDK9uGuXpv2HODJL9cxY/UuGkaHce+wNlzavQmBWvgvUiUUyERE3GItrJsGsx+D\n3WsgoYOzT2a7C52eZj7ox817eWz6WpZvyya5UTQPjmhH/7Pqu12WiN9TIBMRcVtZGaz+r3NXZtYG\nSOwGgx+CVkN8MphZa5m6IoMnv1zH9n0FDGxTnz+OaEe7htFulybitxTIRER8RWkJrPgQvnvCaTTb\nrLcTzJL6uV1ZhQ6WlPLOgi28MGs9Bw6W8OseTblnWBsaRPvmHaQivkyBTETE15QUwdJ3nM7/uRnQ\n/Tdw/uPOBuc+KDu/iJe+2cC/F6QRFBDAmAEtGTOgJRGhvnmjgogvUiATEfFVxQVO1/95E6Bucxj1\nKjTr5XZVx7UlK49/zPiJaSsyqB8Vyj1D2/DrHk0ICvTNGxVEfIkCmYiIr9uyAKbcAjnbnI7/5z7o\ns/3LAJZs3cfj09aSumUfZyVE8uCIZM5tWx/jg+vhRHyFApmIiD84mAtf/tGZymzQCS59DRq0d7uq\n47LWMmP1Tp74Yh1pWfn0bV2PP16QTMfGvrunp4ibFMhERPzJuunw+Z1QmAND/gK9bvfZ3mUARSVl\nvLdwC8/PWk92QTGjujXmvmFtSYwNd7s0EZ+iQCYi4m8O7IHPx8FP06B5Pxg1yen678NyCoqZ9O1G\n3vx+Mwa4uV8Lxp7biqiwYLdLE/EJCmQiIv7IWlg2Gb4Y7/Qqu+BJ6HK1T/YtO9r2ffk889XPTFm6\ng3oRIYw77yyuPrsZwVr4L7WcApmIiD/blwZTxsLW+ZB8MVz0PETUc7uqk1q5PYfHpq/hh017SW4U\nzROXdqJL01i3yxJxTWUDmf7TRUTEF9VNghunwtBH4OcZMLGX89PHdWoSw/uje/HKdT3Ym3eQURO/\n59Gpa8gvKnG7NBGf5rVAZowJM8b8aIxZboxZbYz5WwXnhBpjPjTGbDDGLDTGJHmrHhERvxMQ6LTD\nGD0bIurDe1c4a8wOHnC7shMyxjC8Y0Nm3jOQa85pxuvzNjPsuTl89/Met0sT8VneHCE7CAy21nYB\nugLDjTHlOx/eDOyz1rYGngOe9GI9IiL+qWFHGDPbCWeL/w2v9IOtC92u6qSiw4J59Fed+M+tvQkN\nCuCGN3/k7g+XsTevyO3SRHyO1wKZdRz6z7hgz6P8grVLgH97nn8MDDHqMCgi8ktBoc705U3TwZbC\nW8Ph67852zH5uJ5JcUwf1587h5zF1BXpDHnmW6Ys3Y6/rWEW8SavriEzxgQaY5YBu4GZ1try/0nX\nGNgGYK0tAXIA31+1KiLiluZ94Nbvoes1MO9ZeH0w7F7rdlUnFRoUyD1D2zDtzv4kxUdw94fLueGt\nRWzbm+92aSI+wauBzFpbaq3tCjQBzjbGdDyd6xhjxhhjUo0xqXv2aA2CiNRyYdFwyctw1XuwPwNe\nHQjzX4KyMrcrO6k2DaL4+NY+/G1kBxan7WXYc3N4fe4mSss0Wia1W7XcZWmtzQZmA8PLHdoBNAUw\nxgQBMUBWBZ9/zVqbYq1NqV+/vrfLFRHxD+0uhNt+gNZD4Ks/wdsjIXub21WdVGCA4YY+Scy8ZyB9\nWtXj0WlrGTXxe9ak73e7NBHXePMuy/rGmFjP83BgKLCu3GmfATd4nl8OfGO1qEBEpPIi6zsjZSNf\ngvSlMKkPLHvfaTDr4xJjw3n9hhRevLob6dkFXPzSPP7x5ToKi0vdLk2k2nlzhKwRMNsYswJYhLOG\nbKox5hFjzEjPOW8A9YwxG4B7gPFerEdEpGYyBrpfD7fOgwYd4H+3wke/gbxfTDj4HGMMF3dJ5Ot7\nBnJZ98ZM/HYjwyfMYf7GTLdLE6lW6tQvIlKTlJXC/Bfhm0ehTpwzctZmmNtVVdr3GzJ5cMpKtmTl\nc2VKUx4ckUxMHe2LKf5LnfpFRGqjgEDod5fTt6xOPLz3a/j8Lp9vJntI39bxfDluALcObMXHS7Yz\n5NnvmL4yQy0ypMZTIBMRqYkadnJCWZ87YfG/nGay2350u6pKCQ8JZPwF7fj09r40ignjtslLGP32\nYjJyCtwuTcRrFMhERGqqoFAY9n/OnphlpfDm+TDr//yimSxAx8YxTLmtD38akcy8DXsY+uwc3lmQ\nRplaZEgNpEAmIlLTJfWDsd9Dl2tg7tPw+hDYXf6md98UFBjA6AEt+equgXRrFsufP13Nr19dwPpd\nuW6XJlKlFMhERGqDsGj41ctw5WTYvwNeHQALJvpFM1mAZvXq8PZvz+aZX3dh454DjHhhLhO+/pmD\nJWqRITWDApmISG2SfJHTTLbVYJjxR3jnEr9oJgtOi4zLejRh1j0DubBTIyZ8vZ4LX5jH4i173S5N\n5IwpkImI1DaRCXD1+3DxC7B9MUzqC8s/9ItmsgD1IkOZcFU33rqpJwVFpVz+ygL+/L9V5BYWu12a\nyGlTIBMRqY2MgR43wNh5kJAMU8bAf26AfP8ZbRrUNoGv7h7ATX1a8O7CLQx9dg4z1+xyuyyR06JA\nJiJSm8W1hJumw5C/wrrpMLE3rJ/pdlWVFhEaxF8ubs+U2/oSWyeY0W+ncvvkJezOLXS7NJFTokAm\nIlLbBQRC/3tg9DcQXhcmXw5T74aiPLcrq7SuTWP5/I5+3H9+W2au3cV5z3zHh4u2qqGs+A0FMhER\ncTTqDGO+hd6/h9S3PM1kF7ldVaUFBwZw+6DWfDmuP8mNonngk5Vc88+FbM70n2AptZcCmYiIHBEc\nBuc/Bjd8DqXF8OYwZ1/MUv9ZMN+yfiTvj+7F3y/txKr0HIZPmMPEbzdQXOofLT6kdlIgExGRX2rR\n32km2/kqmPOU00x2z09uV1VpAQGGq89uxqx7BjK4XQL/+PInRr70Pcu3ZbtdmkiFFMhERKRiYTEw\nahJc+S7kbHeayf4wyW+ayQIkRIcx6boevHp9D/bmHWTUxO95dOoa8otK3C5N5BgKZCIicmLJF8PY\nBdBiIHw5Ht75lRPQ/Mj5HRoy856BXHNOM16ft5lhz83hu5/3uF2WyGEKZCIicnJRDeCaD+Hi52F7\nKkzsAys+8ptmsgDRYcE8+qtO/OfW3oQGBXDDmz9y94fL2JvnH5utS82mQCYiIpVjDPS40dNMth38\ndzT850a/aiYL0DMpjunj+nPnkLOYuiKd8579jv8t3aEWGeIqBTIRETk1cS3hpi9gyF9g3VRPM9mv\n3a7qlIQGBXLP0DZMu7M/zevV4a4Pl3HDW4vYtjff7dKkllIgExGRUxcQCP3v9TSTjYXJl8HUe/yq\nmSxAmwZRfHxrH/42sgOL0/Yy7Lk5vD53E6VlGi2T6qVAJiIip69RFxjznaeZ7BvwSn9njZkfCQww\n3NAniZn3DKRPq3o8Om0toyZ+z5r0/W6XJrWIApmIiJyZo5vJlhyEN4bBN4/5VTNZgMTYcF6/IYUX\nr+5GenYBF780j398uY7C4lK3S5NawGuBzBjT1Bgz2xizxhiz2hgzroJzYowxnxtjlnvOuclb9YiI\niJe1GAC3zYfOV8Ccf8Brg2DHErerOiXGGC7uksjX9wzksu6NmfjtRoZPmMP8jZlulyY1nDdHyEqA\ne6217YFewO3GmPblzrkdWGOt7QKcCzxjjAnxYk0iIuJNYTEw6hW4cjLk7XE6/M/4k9+tLYutE8I/\nLu/C5N+dgwWu+edCHvh4BTn5/jXqJ/7Da4HMWpthrV3ieZ4LrAUalz8NiDLGGCAS2IsT5ERExJ8l\nXwS3L4TuN8CCl2BiL9jgX3diAvRtHc+X4wZw68BWfLxkO0Oe/Y7pKzPUIkOqXLWsITPGJAHdgIXl\nDr0EJAPpwEpgnLXWf/bkEBGR4wuPhYsnOC0yAkPh3cvgv7dAXpbblZ2S8JBAxl/Qjk9v70ujmDBu\nm7yE0W8vJiOnwO3SpAYx3k75xphI4DvgMWvtf8sduxzoC9wDtAJmAl2stfvLnTcGGAPQrFmzHlu2\nbPFqzSIiUsWKC2Hu0zDvOWdac/iT0Olyp9msHykpLeOt79N4ZuZPGAy/7ZfEmAGtiAkPdrs08VHG\nmMXW2pSTnufNQGaMCQamAjOstc9WcHwa8IS1dq7n9TfAeGvtj8e7ZkpKik1N9a9bqkVExGPXavjs\nTtiRCq2HwkXPQmwzt6s6Zdv25vP0Vz/x6bJ0YusEc9u5rfhN7yTCggPdLk18TGUDmTfvsjTAG8Da\nisKYx1ZgiOf8BkBbYJO3ahIREZc16AA3f+WMkG2ZDy/3gh8mQZl/tZZoGleH56/qxrQ7+9GlSSyP\nT1/HoKe/5cNFWykp1cobOXVeGyEzxvQD5uKsDTv0T+eDQDMAa+0rxphE4F9AI8DgjJa9e6LraoRM\nRKSGyN7qdPffMBMa94CRLzqBzQ8t2JjFk1+uY9m2bFonRHLfsLac36EBxs+mZKXq+cSUpTcokImI\n1CDWwsqP4csHoDAH+t0N/e9zms36GWstM1bv4qkZ69i4J4+uTWN5YHg7ereq53Zp4iIFMhER8R95\nWfDVn2D5+1DvLLj4eUjq63ZVp6WktIz/LtnBc1//TEZOIQPb1Of+89vSsXGM26WJCxTIRETE/2yY\nBVPvcqYze9wEQ//m3JXphwqLS3l7QRovz95ITkExI7skcu+wNjSvF+F2aVKNFMhERMQ/FeXB7Mfh\nh4kQkQAXPg3JF7td1WnLKSjmtTkbeWPeZkpKLdec04zfD25NQpT/TcvKqVMgExER/7ZjidMiY9dK\nJ5Bd8BREN3K7qtO2e38hL3yzng9+3EZwYAC/69+C0QNaEh2mHmY1mQKZiIj4v9JimP8ifPsEBIXB\nsEeg228goFo2mvGKtMw8nv7qJ6auyKBunWBuH9Sa63o1Vw+zGkqBTEREao6sjfD5OEibC837OYv+\n41u7XdUZWbUjhye/XMfc9ZkkxoRx19A2XNa9CYEBapVRkyiQiYhIzWItLH0HZjwEJYUw8A/QdxwE\n+veU3/wNmTz55TqWb8/hrIRI7j+/LUPbq4dZTaFAJiIiNVPuTvjiD7DmU2jQES5+AZr0cLuqM2Kt\n5ctVO3nqq5/YtCeP7s2cHmbntFQPM3+nQCYiIjXbumkw7V44sAvOuRUG/QlCI92u6oyUlJbx8eLt\nTPh6PTv3FzKobX3+MLwdyY2i3S5NTpMCmYiI1HyFOfD13yD1DYhpBhc9B2ed53ZVZ6ywuJR/zU9j\n4uwN5B4s4ZIuidw7rC1N4+q4XZqcIgUyERGpPbYsgM/vhMyfofOVcP7fIcL/p/ty8ot5Zc5G3vp+\nM6VllmvPac7tg1pTPyrU7dKkkhTIRESkdikuhLnPwLznICwahj8BnX4NNWBx/K79hUz4ej0fpW4j\nNCiA3/Vvyej+LYhSDzOfp0AmIiK106418NkdsCMVWg1xpjHrNne7qiqxac8BnvnqZ6atzCAuIsTT\nw6wZoUHqYearFMhERKT2KiuFRa/DrEfAlsHgP8M5t0BAzQguK7Zn8+SX6/h+QxaNY8O5Z2gbftWt\nsXqY+SAFMhERkextMO0eWP8VJHaHkS9Cw45uV1Vl5q13epit3JFD2wZR3H9+W4YkJ6iHmQ9RIBMR\nEQGnoeyqT+CLB6Aw22kmO+APEFwzNvcuK7N8sWonT3/1E5sz80hpXpcHLmhHz6Q4t0sTFMhERESO\nlb8XZvwJlr8H9Vo72y8l9XO7qipTXFrGR6nbeP7r9ezOPciQdgncP7wt7Rqqh5mbFMhEREQqsvEb\n+PwuyN4C3W+AoY9AeKzbVVWZgqJS3pq/mUnfbuTAwRJGdW3M3UPbqIeZSxTIREREjqcoD779Oyx4\nGSISYMRT0H6k21VVqez8IiZ9t5F/fZ+GtXBtr2b8flBr6kWqh1l1UiATERE5mfSlTouMnSuh3UUw\n4mmIbuR2VVUqI6eA5z09zMKDAxk9oCW/69+SyNAgt0urFRTIREREKqO0GBa8BN8+AYEhzhRm9xsg\nIMDtyqrUht0HeHrGT3y5eif1IkL4/eDWXHOOeph5m+uBzBjTFHgbaABY4DVr7fMVnHcuMAEIBjKt\ntQNPdF0FMhER8YqsjfD5OEibC837Oov+/7+9+w+uqszvOP7+JgQJvwIYEiEhGwQkQQFxsVVxdSW0\nuq5Vq6toWzu123FmZ9fV1nHX2j86nW6ns52t41p31lqtuqNj11W669JVkaAurugqiPxIAiK/FZMA\nQviVkB/f/vGckJsIbMJy8+TefF4zZ3LvuU9uvnfOED55vuc8p3Ba7KpOu9U79vH9l+pYsXkPpWPz\nueePz+G62SXkaA2ztBgIgWwCMMHdV5nZKGAlcL2716SMGQO8BVzl7tvNrMjdG072vgpkIiKSNu7w\n/tOw5B/CrZguvxcuuQuGDI1d2Wnl7ixP1jBb/0kTFWeN4jtXTeeK6VrD7HTrbSBL23ysu+9y91XJ\n4wNALVDSY9ifAYvcfXsy7qRhTEREJK3M4ILb4JvvQsXVsOx78OjlsDO7JgLMjMvOGc8vv3UpD906\nhyOt7fz1k++x8D/fZuW2vbHLG5T6pUFuZuXAHOCdHi+dA4w1s9fNbKWZ/WV/1CMiInJSo4rhpifh\nlmfhyD54bAG8dB+0HEeyyOAAAA2CSURBVIxd2WmVk2NcO3siS//ucv75+vPYvPsQN/54BX/z1Hts\nrD8Qu7xBJe0n9ZvZSOAN4F/cfVGP1x4G5gJVQD6wAviqu2/sMe4O4A6AsrKyL27bti2tNYuIiBzT\n3ATV/xTujVkwKdysfNofxa4qLQ4fbeOJ32zlkdc/4kBLGzNLCqiqLGJBZTHnThytduYpiH4OWVJE\nHrAYeMXdHzjO6/cB+e7+j8nzx4GX3f1nJ3pPnUMmIiJRbH8bXvw27N4AM2+CK/8VRo6PXVVafHbo\nKM++u52lNfW8v2Mf7nDW6GHMryyiqqKIeVMLGZanqzN7I3ogsxCjnwL2uvvdJxhTCTwMXAkMBX4L\n3OLu6070vgpkIiISTVsLLH8Alv875OTC9K/ArIUwpSrrTvzvtPtgC69vaKS6tp5fb2zk0NF2huXl\ncOnUQqoqi6mqKKJodHbcFzQdBkIguxRYDqwFOpLd9wNlAO7+SDLuXuD2ZMxj7v7gyd5XgUxERKJr\n3BBamOtegMN7IH8cnHdDCGelF4aLA7JQS1s772zeS3VtPUtrG/h43xEAZpUWUFVRTFVlkVqbPUQP\nZOmiQCYiIgNGe2u4N+aan0Ld/0FbM4wtD8Fs5s1QODV2hWnj7myoP0B1bQNLa+tZ3aO1uaCyiEum\nqLWpQCYiItKfmpugbnEIZ5vfABwmXhDC2Xk3Zu35Zp12H2zhtboGqmsbWP5haG3m5+Uyb2ohCyqL\nmD9IW5sKZCIiIrE07QrtzDU/hU/XgOXClPkhnFVcDUNHxK4wrVra2nk7aW1Wp7Q2Z5cWUFVZzPyK\nwdPaVCATEREZCBpqYc1zsPZnsH8H5I2Ayj+BWTfD5MshN7tv8u3u1H16IISzuoZjrc0JBcOYXxGW\n1Lh4yplZ29pUIBMRERlIOjpg+4owa7b+59CyH0YWw3lfC+FswuysvRggVeOBFl7b0EB1bT3LP9zN\n4aS1eem00Nq8oqKIolHZ09pUIBMRERmoWpvhwyUhnG18BTpaoXB6CGYzb4KxX4hdYb9obm3n7c17\nqK4NAe2T/c0AzJ40hqqKIqoqi5gxIbNbmwpkIiIimeDwXqj5RWhrbn8r7Cu7BGbdBDOuh+Hj4tbX\nT9yd2l0HWFYXltT4YGdobU4sSBakrSzm4rMzr7WpQCYiIpJpPtsWzjVb81y4I0BOHpxzZZg5m3Yl\n5GVPK+93aTwQrtpcmrQ2j7S2M3xoLpdOLWRBZTFfrhifEa1NBTIREZFM5R6uzuy8GOBgPZxRAOde\nF67ULLsEcnJiV9lvmlvbWbF5D9W19SyrbejW2lxQEWbPKieMGpCtTQUyERGRbNDRDlveCOGs5kVo\nPQSjS0NLc9ZCKKqMXWG/6mxtVtfWs7SugQ927AOgZEw+85Pzzi4aQK1NBTIREZFsc/QQbHgpXAyw\nqRq8Hc6amSw++zUYPSF2hf2u4UBz0tps4M2U1uaXphVSVVHMFRVFjB91RrT6FMhERESy2cFGWL8o\nhLOPVwIGZ1+eLD57DQwbHbvCftfc2s6Kj/ZQXRcWpN21vxkzmF06hgXJhQEVZ/Vva1OBTEREZLDY\nvQnWPhfC2WdbYUh+uCPAzJthahXk5sWusN+5OzW7mo4tqfHBzv1AaG1WJeHsorPHccaQ9LY2FchE\nREQGG3fY+W4IZusWwZG9MPxMOPeGMHNWOndQLD57PA1NzSzrbG1uaqS5tYMb5pTwwMLz0/pzFchE\nREQGs7aj8NGyEM42/ArammHs5BDMZt0MZ06JXWE0na3NsSOGcv6kMWn9WQpkIiIiEjQ3Qe0vQzjb\n8mvAoWRucjHADTCiMHaFWUuBTERERD6v6RNY+3xYRqN+LVguTF0QZs2mXw1Dh8euMKsokImIiMjJ\n1a/vWny26WMYOhIqrw3hbPJlkDMw1vLKZApkIiIi0jsdHbDtN6GlWfMLaGmCEeNh4hwYXwFFM6Co\nItwAXTNofdLbQDakP4oRERGRASwnByZ/KWxX/wA2vhwuBKivgc1vQHtLMtBgbHm4O0BRJYxPvhZO\ngyHxFl/NBgpkIiIi0iVvGJx7fdgA2tvgsy3QUBu2xuTrh0ugoy2MsVwYd3ZXUOsMa2dOGZRroJ0K\nBTIRERE5sdwhYQascBrMuLZrf9tR2LMpCWh10FATtrrF4B1hTE5e+L5js2lJ+3Nsuc5P60GBTERE\nRPpuyFAonhG2VK3NsHtj99m0ne/BuhdSvncYFJ7z+dZnwaTQPh2E0hbIzGwS8BOgGHDgUXf/4QnG\nXgisAG5x9+fTVZOIiIikWd4wmDArbKlaDsLuDV2zaY11sPXNcCHBse8dEWbRjs2mJWFt9MSsv8NA\nOmfI2oB73H2VmY0CVprZq+5ekzrIzHKB7wNL0liLiIiIxHTGSCj5YthSNe8PIS219bnpVVj9dMr3\nFnQPaJ0zayPGZ01QS1sgc/ddwK7k8QEzqwVKgJoeQ+8EXgAuTFctIiIiMkANK4CyPwxbqsN7kwsJ\nktm0hlqoeRGOPNk1Jn9c15IcqWFt+Lh+/QinQ7+cQ2Zm5cAc4J0e+0uAPwWuQIFMREREOg0fB+Xz\nwtbJHQ42dJ9Na6wLi9u2NHWNG1ncff20ohnh+bDR/f85eintgczMRhJmwO5296YeLz8IfNfdO+wk\nU45mdgdwB0BZWVm6ShUREZGBzAxGFYft7C937XcPt4RKvZCgoRZW/QRaD3WNG13afTatdC6Mn97f\nn+K40rpSv5nlAYuBV9z9geO8vgXoTGKFwGHgDnf/+YneUyv1i4iISK90dMD+7d1n0xpqoHFjWOx2\n7tfhms/Fk9Mq+kr9Fqa8HgdqjxfGANx9csr4J4HFJwtjIiIiIr2WkxPWPBtbDtOv6trf0Q57twyo\ntdDS2bKcB9wGrDWz1cm++4EyAHd/JI0/W0REROT4cnKhcGrsKrpJ51WWb9LVjuzN+L9KVy0iIiIi\nA9ngXA5XREREZABRIBMRERGJTIFMREREJDIFMhEREZHIFMhEREREIlMgExEREYlMgUxEREQkMgUy\nERERkcgUyEREREQiS+vNxdPBzBqBbf3wowqB3f3wcyQ9dPwyn45h5tMxzGw6fqfHF9x9/O8alHGB\nrL+Y2Xu9uTu7DEw6fplPxzDz6RhmNh2//qWWpYiIiEhkCmQiIiIikSmQndijsQuQ34uOX+bTMcx8\nOoaZTcevH+kcMhEREZHINEMmIiIiEpkCWQ9mdpWZbTCzTWZ2X+x6pG/MbJKZvWZmNWa23szuil2T\n9J2Z5ZrZ+2a2OHYt0ndmNsbMnjezOjOrNbOLY9ckfWNmf5v8Dl1nZs+a2bDYNWU7BbIUZpYL/Aj4\nCjADuNXMZsStSvqoDbjH3WcAFwHf1DHMSHcBtbGLkFP2Q+Bld68AZqNjmVHMrAT4NjDX3c8DcoFb\n4laV/RTIuvsDYJO7b3b3o8D/ANdFrkn6wN13ufuq5PEBwn8EJXGrkr4ws1Lgq8BjsWuRvjOzAuAy\n4HEAdz/q7vviViWnYAiQb2ZDgOHAJ5HryXoKZN2VADtSnu9E/5lnLDMrB+YA78StRProQeA7QEfs\nQuSUTAYagSeStvNjZjYidlHSe+7+MfADYDuwC9jv7kviVpX9FMgkK5nZSOAF4G53b4pdj/SOmV0D\nNLj7yti1yCkbAlwA/Njd5wCHAJ2Pm0HMbCyhOzQZmAiMMLO/iFtV9lMg6+5jYFLK89Jkn2QQM8sj\nhLFn3H1R7HqkT+YB15rZVsIpA/PN7Om4JUkf7QR2unvnzPTzhIAmmWMBsMXdG929FVgEXBK5pqyn\nQNbdu8A0M5tsZkMJJzG+GLkm6QMzM8K5K7Xu/kDseqRv3P3v3b3U3csJ//6Wubv+Ms8g7v4psMPM\npie7qoCaiCVJ320HLjKz4cnv1Cp0YUbaDYldwEDi7m1m9i3gFcJVJf/t7usjlyV9Mw+4DVhrZquT\nffe7+68i1iQy2NwJPJP8YbsZuD1yPdIH7v6OmT0PrCJcuf4+WrU/7bRSv4iIiEhkalmKiIiIRKZA\nJiIiIhKZApmIiIhIZApkIiIiIpEpkImIiIhEpkAmIlnFzNrNbHXKdtpWiTezcjNbd7reT0Skk9Yh\nE5Fsc8Tdz49dhIhIX2iGTEQGBTPbamb/ZmZrzey3ZjY12V9uZsvMbI2ZVZtZWbK/2Mz+18w+SLbO\nW8fkmtl/mdl6M1tiZvnRPpSIZA0FMhHJNvk9WpYLU17b7+4zgYeBB5N9/wE85e6zgGeAh5L9DwFv\nuPtswr0YO+/aMQ34kbufC+wDbkzz5xGRQUAr9YtIVjGzg+4+8jj7twLz3X1zcgP6T939TDPbDUxw\n99Zk/y53LzSzRqDU3VtS3qMceNXdpyXPvwvkufv30v/JRCSbaYZMRAYTP8HjvmhJedyOzsUVkdNA\ngUxEBpOFKV9XJI/fAm5JHv85sDx5XA18A8DMcs2soL+KFJHBR3/ZiUi2yTez1SnPX3b3zqUvxprZ\nGsIs163JvjuBJ8zsXqARuD3ZfxfwqJl9nTAT9g1gV9qrF5FBSeeQicigkJxDNtfdd8euRUSkJ7Us\nRURERCLTDJmIiIhIZJohExEREYlMgUxEREQkMgUyERERkcgUyEREREQiUyATERERiUyBTERERCSy\n/wdH2zzl+1RNwwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F49KqoONLe63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb35f070-9256-4210-c1d1-122289dc7155"
      },
      "source": [
        "n_layers = 3\n",
        "n_hidden = 512\n",
        "dropout = 0.7\n",
        "lr = 0.001\n",
        "\n",
        "model = CharRNN(chars,\n",
        "                n_hidden=n_hidden, \n",
        "                n_layers=n_layers, \n",
        "                dropout=dropout,\n",
        "                mode='RNN').to(device)\n",
        "\n",
        "printParams(model)\n",
        "\n",
        "train_loss, valid_loss = train(model, text, epochs=10, seq_length=300, \n",
        "                               batch_size=512, save_rate=None)\n",
        "\n",
        "plot_loss(train_loss, valid_loss, 10, 'RNN')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name:    rnn.weight_ih_l0, shape:    torch.Size([512, 112]), total params:      57344, grad params:      57344\n",
            "Name:    rnn.weight_hh_l0, shape:    torch.Size([512, 512]), total params:     262144, grad params:     262144\n",
            "Name:      rnn.bias_ih_l0, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:      rnn.bias_hh_l0, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:    rnn.weight_ih_l1, shape:    torch.Size([512, 512]), total params:     262144, grad params:     262144\n",
            "Name:    rnn.weight_hh_l1, shape:    torch.Size([512, 512]), total params:     262144, grad params:     262144\n",
            "Name:      rnn.bias_ih_l1, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:      rnn.bias_hh_l1, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:    rnn.weight_ih_l2, shape:    torch.Size([512, 512]), total params:     262144, grad params:     262144\n",
            "Name:    rnn.weight_hh_l2, shape:    torch.Size([512, 512]), total params:     262144, grad params:     262144\n",
            "Name:      rnn.bias_ih_l2, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:      rnn.bias_hh_l2, shape:         torch.Size([512]), total params:        512, grad params:        512\n",
            "Name:           fc.weight, shape:    torch.Size([112, 512]), total params:      57344, grad params:      57344\n",
            "Name:             fc.bias, shape:         torch.Size([112]), total params:        112, grad params:        112\n",
            "\n",
            "Total number of parameters is 1428592\n",
            "Epoch 1:\n",
            "Train loss: 3.931\n",
            "Valid loss: 3.389\n",
            "Generated text for prefix 'Абай': Абай еа    ан  еа н аа е н ыаыанаые   ааеаее  аеааееынеаына е нанын а  ынн ан ааа аенаеаа ее  на ыеыене \n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "Train loss: 3.775\n",
            "Valid loss: 3.375\n",
            "Generated text for prefix 'Абай': Абайыаыыаа аные  а ы е аыы ан еееыныне аа неее  еааа аынеаеые     ана н а ыена ае ын енаыаа   ын ыыыене \n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "Train loss: 3.552\n",
            "Valid loss: 3.374\n",
            "Generated text for prefix 'Абай': Абай  ы   аае  аеаанраы ннаеа  аае нн ыаеааааеаеыанаа     а   ыаеыанеаы   н а а   ын а  ыа  еа ееенр  ар\n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "Train loss: 3.500\n",
            "Valid loss: 12.128\n",
            "Generated text for prefix 'Абай': АбайррФФҺҺҺҺҺ__Ф_IҺҺҺҺIФ_=Һ_II;Ф_ФФФҺФҺҺI=ФҺҺ=_ФФ_ҺIҺҺҺҺҺҺ=ҺҺФФҺ=ҺФФIҺҺҺ_IҺФФ_ФФФҺ_Ф_ФI==IФФ;ФФФФФҺҺ_ҺҺФ\n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "Train loss: 5.005\n",
            "Valid loss: 3.399\n",
            "Generated text for prefix 'Абай': Абайа е ы    нынн н ы ааыа ын ааеа  ыен е аан  ыа а ее а аа е   н на  ае а е ее нааае  ааы ае  не ыы  е \n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "Train loss: 3.505\n",
            "Valid loss: 3.371\n",
            "Generated text for prefix 'Абай': Абайеееа ана ааеееын н  еаен еае нае   е ы  еы аеаы  ананн ыее аеана н е   ае нааынеаы  ааае а еан аае н\n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "Train loss: 3.464\n",
            "Valid loss: 3.366\n",
            "Generated text for prefix 'Абай': Абай еае  ы неыыеа е  ааее ыны ы ы а  н  н  на  ыыыые ы  еыыае а  нан н ееы  еыааааеааанан   ааа аааеаыа\n",
            "\n",
            "Time elapsed 0.18 minutes\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "Train loss: 3.436\n",
            "Valid loss: 3.366\n",
            "Generated text for prefix 'Абай': Абай  а не нан ааын аеааы анн нна е   аы а аа а ынаые ааные а нан  е  ыаааа ые е аы  ы ане ы е    наееы \n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "Train loss: 3.416\n",
            "Valid loss: 3.367\n",
            "Generated text for prefix 'Абай': Абайыанынеыааа      аына ее аеыы н ы   ы а ааее а а ан ы   еааеа а   на ы  ыые ы на  е ы ыыаа а аа аы  ы\n",
            "\n",
            "Time elapsed 0.19 minutes\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "Train loss: 3.402\n",
            "Valid loss: 3.367\n",
            "Generated text for prefix 'Абай': Абайеыееа   аыеыаны ы ен ыыееныан а аа еаеенаеее     а аа ыан аа а  е ы н  нны еыае  нн  нееааныынна  ае\n",
            "\n",
            "Time elapsed 0.18 minutes\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFNCAYAAABIc7ibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTERERMQHCmEiIiIiPvh/qHkSDuf1bxIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uzWQhuhKe4j",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Pretrained models\n",
        "I actually trained these models for 200 epochs and saved them (but, their class definitions were different). So, I am going to load in these models, and get their outputs.\n",
        "\n",
        "\n",
        "### LSTM model 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WdpEp30RKMNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "ce253d8d-5411-436d-e1b8-b9d31f831d50"
      },
      "source": [
        "class CharLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self, tokens, n_hidden=256, n_layers = 2, \n",
        "               dropout = 0.5, lr=0.001):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_val = dropout\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.chars = tokens\n",
        "    self.char2int = {cc: ii for ii, cc in enumerate(tokens)}\n",
        "    self.int2char = {ii: cc for cc, ii in self.char2int.items()}\n",
        "    \n",
        "    self.lstm = nn.LSTM(len(tokens), n_hidden, n_layers, \n",
        "                        batch_first = True, dropout = dropout)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_hidden, len(tokens))\n",
        "    \n",
        "  def forward(self, b_x, h=None):\n",
        "    \n",
        "    b_x, h = self.lstm(b_x, h)\n",
        "    b_x = self.dropout(b_x)\n",
        "    b_x = b_x.contiguous().view(-1, self.n_hidden)\n",
        "    b_x = self.fc(b_x)\n",
        "    \n",
        "    return b_x, h\n",
        "  \n",
        "model = load_model('modelEpoch_200_lstm', CharLSTM).to(device)\n",
        "\n",
        "print(sample(model, 5, 2000))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Абай қарық жақсы елдің\n",
            "тесебіне болды да қалып, жаңа боп алды. Бес сөзді астаған жерінің күңгісі келді. Барлық қоса жастықтар жағындағы киімдері бірі түріне біреу\n",
            "көрінсін ғана тілегін қарап кетті.\n",
            "\n",
            "Бардың қайсары жайын, жаны да жірек\n",
            "ала құндай. Қазыр біті болған күліп жарап жүріп қапты. Бірақ\n",
            "алғашқы жоғынды жайлай, болмайды. Абай басқа кезге келді. Бозымақтан, жүрегі күйде бұрын жатып қалды.\n",
            "\n",
            "– Жаңағы қайраны жоқ. Бірақ қолан жайлап, жалаңақ, айдасыз қалам. Құл аттың ауырып келетін ел көңілімен\n",
            "жарайтқан ауылдардың айтқанына жақан қолына берген жұртты алыстан, жылаған бірдей қалың жалған жүзі де боран жете жатты.\n",
            "\n",
            "Абай сыртқа байқады.\n",
            "\n",
            "Құнанбай болды да:\n",
            "\n",
            "– Жор сонау бермейміз, таңырып, аламыздығы мастаным етті дейді. Сен жар айтып тастамаймын! - деп айтты.\n",
            "\n",
            "– Ене барады» десе, жайлау қылды.\n",
            "\n",
            "– Абай, айтыңыз білмейді?.. - деп, жалғыз жеткізбей, бұрын қарады. Барлық құра боп\n",
            "қалған жақын қалған. Арада кірісті. Ол сөздің\n",
            "ар болмаса,\n",
            "тоқтап қалды.\n",
            "\n",
            "Бірақ айтқаным да жанған жеңдей қара құйды.\n",
            "\n",
            "Барысына, алдақынан жүрген қара қара құнанды құнан қайтараның сары кеткілгенін қалың болды.\n",
            "\n",
            "Абайдың жалғыз кейін\n",
            "салып жүрген күйін болатын деген жоқ-жы. Бұл қарыздың қорқылысы еді. Балаларын жақсы жасарып, бұрын қыралып, жақынына түсіп, сөйлесе береді. Қайта қыстаулық\n",
            "жақындықты.\n",
            "\n",
            "Бірақ сенік артына басқа аузына барып жырқыларып, каторлап қайтпақ болғанда, жең\n",
            "алып, бетін келеді. Бірақ таң\n",
            "кішкенше жақсы бала босамайды.\n",
            "\n",
            "Осы жалған айыққан жанға қарай ауылдың қарасы дейтін. Оның айнағасы мен сылапан табасы бар. Айдап жетіп, соңғы боп, салып,\n",
            "аласызып жүрді. Құнанбай қатты келгенде, жаналаса, қасы аталады.\n",
            "\n",
            "Қамқаның жақын айдай жүріп, жүрген жоқ. Бірақ барлық көшінің қызы де жүреді. Бірақ\n",
            "сол кімістігіне жақын кiрісті да, бұйрығын бестіні тілеп алды. Баламаның аламалығы да күн басында жатқан сынысы жоқ. Семіз кешекес толық жер боп, қатып\n",
            "келгенде, көп жар бар, балаларын теп ап, барып, жүзінен жең аттап алды. Оны біліп,\n",
            "тынышқан бір\n",
            "алысқа көп кәрі, аталыс тегіс кітіс бір жала атта\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23w92CnARY8p",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### GRU model 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUvVdpdeKMNi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "9b5928e1-affe-4ff7-b543-a4d07512d271"
      },
      "source": [
        "class CharGRU(nn.Module):\n",
        "  \n",
        "  def __init__(self, tokens, n_hidden=256, n_layers = 2, \n",
        "               dropout = 0.5, lr=0.001):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_val = dropout\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.chars = tokens\n",
        "    self.char2int = {cc: ii for ii, cc in enumerate(tokens)}\n",
        "    self.int2char = {ii: cc for cc, ii in self.char2int.items()}\n",
        "    \n",
        "    self.gru = nn.GRU(len(tokens), n_hidden, n_layers, \n",
        "                      batch_first = True, dropout = dropout)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_hidden, len(tokens))\n",
        "    \n",
        "  def forward(self, b_x, h=None):\n",
        "    \n",
        "    b_x, h = self.gru(b_x, h)\n",
        "    b_x = self.dropout(b_x)\n",
        "    b_x = b_x.contiguous().view(-1, self.n_hidden)\n",
        "    b_x = self.fc(b_x)\n",
        "    \n",
        "    return b_x, h\n",
        "\n",
        "model = load_model('modelEpoch_200_gru', CharGRU).to(device)\n",
        "\n",
        "print(sample(model, 5, 2000))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Абайды. Біреу болған бала соны білгірген\n",
            "екен. Сөзіне сайлауы жас айдап, жолға көп сүйді. Құнанбай мен Жабайды\n",
            "астан түре алып келген еді. Қарсы, бір-ақ келін беретін. Ол бұл екен\n",
            "деген бойы жас көрінеді. Бірақ олардың көзі жатыр, сенім де, осы\n",
            "ауған күндің ауылдың қалың сүйініп құшақтап, тұрып айтқан.\n",
            "\n",
            "Бірақ қандап осы ауылдар бар ат білмейтін.\n",
            "\n",
            "Сынымен бір сәтте Құнанбай жол бойында топырып тастап, түгел қарап,\n",
            "тағы қола болып еді. Барлы сол Абайды көріп, сыр бар еткен соң,\n",
            "Абай арқаға кезектеп жатпай, сала тастады. Байтас батыр жасырын\n",
            "қарсы алғандай. Сонысы екен. Жұмағұл бұл кезде айтпақан арасында бар еді.\n",
            "Қыстақ берген қырылын тезінен бірі күндік, салалан сала білдірген жаңа\n",
            "қосыла сол күрік бай қатты арттарынан қарайға қайтады. Сөзді айтқандай\n",
            "болатын. Абайды құлай бүріп, алысқан бар дән бір сауат бұрып қалған\n",
            "кім ағып, қып тұр.\n",
            "\n",
            "– Барым қара қыстарды алдың де керетті!\n",
            "\n",
            "– Сол жалған жатқан қанымыздан айналысқа басып:\n",
            "\n",
            "– Қоныс көп ағайылындарың, аран! Бірең сөрсі де артырасың! - деді. Осы\n",
            "арада қыстаудың қарынан, жең жайын жала бастап, жүрек күйін айтып\n",
            "қалған.\n",
            "\n",
            "Барсын да жақын жайы осындай болған болатын. Онан сары бір сөзі\n",
            "қонақтарға ақырып жатыр еді. Құнанбай жақан қарып тұрған жағында жатқан\n",
            "жері болатын.\n",
            "\n",
            "Абайдың күн жаңылып, тұрып, тағы да таңдайын қатты болатын.\n",
            "\n",
            "Бұл екі күндер балалақ емес тіледі.. Қытқа алған-сол, жақындар дос\n",
            "жүнді.\n",
            "\n",
            "Алшынбайдың асыл көзі жосыны асып, кейін қосып, бірез қылғаш тұр еткен\n",
            "қолын ерекше кеңдесіп тұрып тұрып, қатты байып қып тұрды. Базаралы бір\n",
            "қалып еді.\n",
            "\n",
            "Абайдың және біз байлауы ала бергенде, алыстай, күйін айтқан.\n",
            "\n",
            "Соны айтқызған жоқ. Қара көшілері де қатты созаларды енді қалаға\n",
            "көрінген.\n",
            "\n",
            "Қаратой күйеудің барласа да тұр екен. Оның жас қыстауы жайының жауыны\n",
            "жақыл болатын. Осы ауылдаң басқа қайта бұл топтың көңілі жандара жанып\n",
            "тұр.\n",
            "\n",
            "Құнанбай боп бала жолға жалғыз жүзі тартып, қолын қыстиды да: - Қартық\n",
            "жүрген басын басы бар. Жалынып құсыққан көп екен.\n",
            "\n",
            "Абай содан бір аттылар тартып қалған екен. Байқасындай сияқты сөніле\n",
            "қ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Q-3PZzRdVN",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### RNN model 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGidMcqdKMNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "8f41f7ff-817a-4477-ed86-a80c71248d4b"
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, tokens, n_hidden=256, n_layers = 2, \n",
        "               dropout = 0.5, lr=0.001):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_val = dropout\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.chars = tokens\n",
        "    self.char2int = {cc: ii for ii, cc in enumerate(tokens)}\n",
        "    self.int2char = {ii: cc for cc, ii in self.char2int.items()}\n",
        "    \n",
        "    self.rnn = nn.RNN(len(tokens), n_hidden, n_layers, \n",
        "                      batch_first = True, dropout = dropout)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_hidden, len(tokens))\n",
        "    \n",
        "  def forward(self, b_x, h=None):\n",
        "    \n",
        "    b_x, h = self.rnn(b_x, h)\n",
        "    b_x = self.dropout(b_x)\n",
        "    b_x = b_x.contiguous().view(-1, self.n_hidden)\n",
        "    b_x = self.fc(b_x)\n",
        "    \n",
        "    return b_x, h\n",
        "\n",
        "model = load_model('modelEpoch_200_rnn', CharRNN).to(device)\n",
        "\n",
        "print(sample(model, 5, 2000))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Абайың,\n",
            "көріміс босында қайса, тартып ап, артың жалғыз жүргеніндi берiп отырғың, қалай\n",
            "бұлалған жалайды.\n",
            "\n",
            "Бірақ жақын жүрген сыңынан бiрдіңдiң\n",
            "бiстер бай боп қалғын жоқ, түн бетін тарып, қайдан болса ды. Осы көшi екен. Боқарым жеке сеттi.\n",
            "\n",
            "Ой жоқ тағаны ескі жаққа каткен жақын таңғанған болған, бiр қылға кісiнi кiргені алған, сағы баласы, жал қатқар болат атты да алап қалды. Барсын айлыптың бал салдар күрiсiн еретіп жатқанды, арындар болатын. Сон сойтын қолға\n",
            "жыбарын бұл екi жоқ.\n",
            "\n",
            "Боларары\n",
            "қарында бар болатын!\n",
            " Абай бар жоқ бейге толағы көзге қарай күлгесің, келіп, жүргіз жақаны болырта жарағып, жарандың аса бұрын дәрсіз дылдарына қарсы жатарын тысын болмасан сенiң ма?\n",
            "\n",
            "Құлақ балып кіпінен жатып, жайылап берiп, қыйлайдан қалаң топ күн бiр атын жердiң, жүні айтатын\n",
            "болып келді.\n",
            " Балағызы, болары тасырап қайда қарылды. Ой ештер бағыны жоқ. Сүнді бетендерін, саған араз салған жоқ. Бірақ сала мен\n",
            "келді. Осы күзі байырып, жарастырды. Осы баламыл бір қыста жақыр бойын айтырған жылы атаулыра, жалғаз көп көзінен қалғоның бала тұрып, арты айтты.\n",
            "\n",
            "–\n",
            "Еедеріне сойғандай. Сон мен жарған жерiнде қырқана айтап алып кеткіндей. Сүгелiнiң өзін құлақ құлық айтып, ауылдар кеттi. Болытып күстi. Солар бiр күне байланып:\n",
            "\n",
            "– Абай теген қасана тайтып тапты. Бірас қарағасында боп көрiп\n",
            "керек, сол бері жесегi қарақсы берiп кетiпті.\n",
            "Абайдың арылдай жақын, сөзге жерекен болыт жарқ болда да алғұн.\n",
            "\n",
            "Қозырысын балып келеді. Азалды ауны салып: \n",
            "– Енді осы бір ауылдар астынан, сарғалы екке жақан ауландай,,\n",
            "бір басы де, түр жақана қылған жолында осы көңiлiнде\n",
            "Арасында қолға қарай берде түсiп қаласанып еліп та жесерінін ені жетті. Осанеді де\n",
            "келдіңдер болған. Олардан, арандық болады? – деп,. Қала бұл қайарымыңдар бар. Абыйға қарый жүйес болғанда, алдында көп жүгөнесінің берi жеткен боласың етi болада.\n",
            "\n",
            "Бұлыр да бар екен! - деген. Бұр сөзінде көз елiп, қайты жатып, олыс айтады.\n",
            "\n",
            "Құдарбек қастыр тартыстап жатқандық солып барған болда, осынан бiр алып, жалын қатты айықтарынан берiп жатқанының жал қосып, сөп \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}